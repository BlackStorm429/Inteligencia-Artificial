{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+---------+------------+------+----------+------------+---------------+\n",
      "|   |    antecedents     |    consequents     | antecedent support | consequent support | support | confidence | lift | leverage | conviction | zhangs_metric |\n",
      "+---+--------------------+--------------------+--------------------+--------------------+---------+------------+------+----------+------------+---------------+\n",
      "| 0 | frozenset({'Não'}) | frozenset({'Sim'}) |        1.0         |        1.0         |   1.0   |    1.0     | 1.0  |   0.0    |    inf     |      0.0      |\n",
      "| 1 | frozenset({'Sim'}) | frozenset({'Não'}) |        1.0         |        1.0         |   1.0   |    1.0     | 1.0  |   0.0    |    inf     |      0.0      |\n",
      "+---+--------------------+--------------------+--------------------+--------------------+---------+------------+------+----------+------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Carregue os dados do arquivo CSV\n",
    "base = pd.read_csv('mercado.csv', sep=',', encoding='utf-8')\n",
    "\n",
    "# Converta os dados em uma lista de listas para o TransactionEncoder\n",
    "transactions = []\n",
    "for i in range(len(base)):\n",
    "    transactions.append([str(item).strip() for item in base.iloc[i, 1:].values if pd.notnull(item)])\n",
    "\n",
    "# Inicialize o TransactionEncoder e o transforme com os dados\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Aplique o algoritmo Apriori para encontrar os itemsets frequentes\n",
    "frequent_itemsets = apriori(df, min_support=0.3, use_colnames=True)\n",
    "\n",
    "# Gere as regras de associação\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.8)\n",
    "\n",
    "# Converta as regras de associação para um DataFrame do Pandas\n",
    "rules_df = pd.DataFrame(rules)\n",
    "\n",
    "# Exiba as regras de associação em uma tabela visual\n",
    "print(tabulate(rules_df, headers='keys', tablefmt='pretty'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
