{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68217453\n",
      "Iteration 2, loss = 0.66165764\n",
      "Iteration 3, loss = 0.64535797\n",
      "Iteration 4, loss = 0.63231911\n",
      "Iteration 5, loss = 0.62153003\n",
      "Iteration 6, loss = 0.61374681\n",
      "Iteration 7, loss = 0.60871631\n",
      "Iteration 8, loss = 0.60476825\n",
      "Iteration 9, loss = 0.60078853\n",
      "Iteration 10, loss = 0.59838970\n",
      "Iteration 11, loss = 0.59575254\n",
      "Iteration 12, loss = 0.59284718\n",
      "Iteration 13, loss = 0.58962832\n",
      "Iteration 14, loss = 0.58618174\n",
      "Iteration 15, loss = 0.58235601\n",
      "Iteration 16, loss = 0.57831949\n",
      "Iteration 17, loss = 0.57420073\n",
      "Iteration 18, loss = 0.57004718\n",
      "Iteration 19, loss = 0.56582559\n",
      "Iteration 20, loss = 0.56184178\n",
      "Iteration 21, loss = 0.55812071\n",
      "Iteration 22, loss = 0.55482401\n",
      "Iteration 23, loss = 0.55166058\n",
      "Iteration 24, loss = 0.54879069\n",
      "Iteration 25, loss = 0.54627353\n",
      "Iteration 26, loss = 0.54363291\n",
      "Iteration 27, loss = 0.54126664\n",
      "Iteration 28, loss = 0.53875090\n",
      "Iteration 29, loss = 0.53648381\n",
      "Iteration 30, loss = 0.53386799\n",
      "Iteration 31, loss = 0.53205849\n",
      "Iteration 32, loss = 0.53022502\n",
      "Iteration 33, loss = 0.52837930\n",
      "Iteration 34, loss = 0.52672402\n",
      "Iteration 35, loss = 0.52452623\n",
      "Iteration 36, loss = 0.52242503\n",
      "Iteration 37, loss = 0.52055299\n",
      "Iteration 38, loss = 0.51845371\n",
      "Iteration 39, loss = 0.51685214\n",
      "Iteration 40, loss = 0.51508304\n",
      "Iteration 41, loss = 0.51357690\n",
      "Iteration 42, loss = 0.51190156\n",
      "Iteration 43, loss = 0.50985597\n",
      "Iteration 44, loss = 0.50803716\n",
      "Iteration 45, loss = 0.50663474\n",
      "Iteration 46, loss = 0.50465885\n",
      "Iteration 47, loss = 0.50293074\n",
      "Iteration 48, loss = 0.50132471\n",
      "Iteration 49, loss = 0.49968178\n",
      "Iteration 50, loss = 0.49819136\n",
      "Iteration 51, loss = 0.49696963\n",
      "Iteration 52, loss = 0.49624178\n",
      "Iteration 53, loss = 0.49511192\n",
      "Iteration 54, loss = 0.49464732\n",
      "Iteration 55, loss = 0.49290270\n",
      "Iteration 56, loss = 0.49075618\n",
      "Iteration 57, loss = 0.48826617\n",
      "Iteration 58, loss = 0.48694961\n",
      "Iteration 59, loss = 0.48530069\n",
      "Iteration 60, loss = 0.48431664\n",
      "Iteration 61, loss = 0.48320576\n",
      "Iteration 62, loss = 0.48175625\n",
      "Iteration 63, loss = 0.48004743\n",
      "Iteration 64, loss = 0.47835036\n",
      "Iteration 65, loss = 0.47671517\n",
      "Iteration 66, loss = 0.47512038\n",
      "Iteration 67, loss = 0.47372787\n",
      "Iteration 68, loss = 0.47272603\n",
      "Iteration 69, loss = 0.47143142\n",
      "Iteration 70, loss = 0.47004354\n",
      "Iteration 71, loss = 0.46872995\n",
      "Iteration 72, loss = 0.46710288\n",
      "Iteration 73, loss = 0.46579663\n",
      "Iteration 74, loss = 0.46486164\n",
      "Iteration 75, loss = 0.46347868\n",
      "Iteration 76, loss = 0.46198398\n",
      "Iteration 77, loss = 0.46064053\n",
      "Iteration 78, loss = 0.45937872\n",
      "Iteration 79, loss = 0.45779730\n",
      "Iteration 80, loss = 0.45613379\n",
      "Iteration 81, loss = 0.45456794\n",
      "Iteration 82, loss = 0.45292485\n",
      "Iteration 83, loss = 0.45237885\n",
      "Iteration 84, loss = 0.45198279\n",
      "Iteration 85, loss = 0.45144260\n",
      "Iteration 86, loss = 0.45032235\n",
      "Iteration 87, loss = 0.44911413\n",
      "Iteration 88, loss = 0.44781536\n",
      "Iteration 89, loss = 0.44611019\n",
      "Iteration 90, loss = 0.44415188\n",
      "Iteration 91, loss = 0.44202253\n",
      "Iteration 92, loss = 0.44057664\n",
      "Iteration 93, loss = 0.43925309\n",
      "Iteration 94, loss = 0.43908880\n",
      "Iteration 95, loss = 0.43805809\n",
      "Iteration 96, loss = 0.43677716\n",
      "Iteration 97, loss = 0.43539389\n",
      "Iteration 98, loss = 0.43420898\n",
      "Iteration 99, loss = 0.43270842\n",
      "Iteration 100, loss = 0.43116280\n",
      "Iteration 101, loss = 0.42949332\n",
      "Iteration 102, loss = 0.42807229\n",
      "Iteration 103, loss = 0.42740762\n",
      "Iteration 104, loss = 0.42732350\n",
      "Iteration 105, loss = 0.42665015\n",
      "Iteration 106, loss = 0.42561306\n",
      "Iteration 107, loss = 0.42400290\n",
      "Iteration 108, loss = 0.42178306\n",
      "Iteration 109, loss = 0.41941855\n",
      "Iteration 110, loss = 0.41733018\n",
      "Iteration 111, loss = 0.41690934\n",
      "Iteration 112, loss = 0.41636495\n",
      "Iteration 113, loss = 0.41537940\n",
      "Iteration 114, loss = 0.41370682\n",
      "Iteration 115, loss = 0.41205791\n",
      "Iteration 116, loss = 0.41020702\n",
      "Iteration 117, loss = 0.40875449\n",
      "Iteration 118, loss = 0.40738544\n",
      "Iteration 119, loss = 0.40598672\n",
      "Iteration 120, loss = 0.40479891\n",
      "Iteration 121, loss = 0.40360435\n",
      "Iteration 122, loss = 0.40259320\n",
      "Iteration 123, loss = 0.40131034\n",
      "Iteration 124, loss = 0.40002247\n",
      "Iteration 125, loss = 0.39870091\n",
      "Iteration 126, loss = 0.39757186\n",
      "Iteration 127, loss = 0.39616718\n",
      "Iteration 128, loss = 0.39507364\n",
      "Iteration 129, loss = 0.39394791\n",
      "Iteration 130, loss = 0.39273510\n",
      "Iteration 131, loss = 0.39145206\n",
      "Iteration 132, loss = 0.39045208\n",
      "Iteration 133, loss = 0.38927096\n",
      "Iteration 134, loss = 0.38804927\n",
      "Iteration 135, loss = 0.38669341\n",
      "Iteration 136, loss = 0.38551858\n",
      "Iteration 137, loss = 0.38434612\n",
      "Iteration 138, loss = 0.38366908\n",
      "Iteration 139, loss = 0.38251039\n",
      "Iteration 140, loss = 0.38133970\n",
      "Iteration 141, loss = 0.38047875\n",
      "Iteration 142, loss = 0.37941927\n",
      "Iteration 143, loss = 0.37894389\n",
      "Iteration 144, loss = 0.37765397\n",
      "Iteration 145, loss = 0.37636960\n",
      "Iteration 146, loss = 0.37498483\n",
      "Iteration 147, loss = 0.37376776\n",
      "Iteration 148, loss = 0.37240949\n",
      "Iteration 149, loss = 0.37126709\n",
      "Iteration 150, loss = 0.37039809\n",
      "Iteration 151, loss = 0.37008725\n",
      "Iteration 152, loss = 0.36911264\n",
      "Iteration 153, loss = 0.36769621\n",
      "Iteration 154, loss = 0.36609990\n",
      "Iteration 155, loss = 0.36447470\n",
      "Iteration 156, loss = 0.36336181\n",
      "Iteration 157, loss = 0.36244753\n",
      "Iteration 158, loss = 0.36150440\n",
      "Iteration 159, loss = 0.36054235\n",
      "Iteration 160, loss = 0.35946590\n",
      "Iteration 161, loss = 0.35817144\n",
      "Iteration 162, loss = 0.35654244\n",
      "Iteration 163, loss = 0.35541014\n",
      "Iteration 164, loss = 0.35396095\n",
      "Iteration 165, loss = 0.35283345\n",
      "Iteration 166, loss = 0.35182924\n",
      "Iteration 167, loss = 0.35047577\n",
      "Iteration 168, loss = 0.34939875\n",
      "Iteration 169, loss = 0.34824738\n",
      "Iteration 170, loss = 0.34723602\n",
      "Iteration 171, loss = 0.34629732\n",
      "Iteration 172, loss = 0.34513493\n",
      "Iteration 173, loss = 0.34392455\n",
      "Iteration 174, loss = 0.34270456\n",
      "Iteration 175, loss = 0.34166025\n",
      "Iteration 176, loss = 0.34048101\n",
      "Iteration 177, loss = 0.33934808\n",
      "Iteration 178, loss = 0.33823294\n",
      "Iteration 179, loss = 0.33719694\n",
      "Iteration 180, loss = 0.33601416\n",
      "Iteration 181, loss = 0.33467515\n",
      "Iteration 182, loss = 0.33369272\n",
      "Iteration 183, loss = 0.33256759\n",
      "Iteration 184, loss = 0.33153595\n",
      "Iteration 185, loss = 0.33035514\n",
      "Iteration 186, loss = 0.32921045\n",
      "Iteration 187, loss = 0.32813269\n",
      "Iteration 188, loss = 0.32682433\n",
      "Iteration 189, loss = 0.32547840\n",
      "Iteration 190, loss = 0.32480400\n",
      "Iteration 191, loss = 0.32471343\n",
      "Iteration 192, loss = 0.32366818\n",
      "Iteration 193, loss = 0.32233532\n",
      "Iteration 194, loss = 0.32091325\n",
      "Iteration 195, loss = 0.31977577\n",
      "Iteration 196, loss = 0.31831958\n",
      "Iteration 197, loss = 0.31701658\n",
      "Iteration 198, loss = 0.31571431\n",
      "Iteration 199, loss = 0.31469194\n",
      "Iteration 200, loss = 0.31359391\n",
      "Iteration 201, loss = 0.31250982\n",
      "Iteration 202, loss = 0.31156905\n",
      "Iteration 203, loss = 0.31052543\n",
      "Iteration 204, loss = 0.30941264\n",
      "Iteration 205, loss = 0.30853943\n",
      "Iteration 206, loss = 0.30787951\n",
      "Iteration 207, loss = 0.30686185\n",
      "Iteration 208, loss = 0.30573129\n",
      "Iteration 209, loss = 0.30463549\n",
      "Iteration 210, loss = 0.30356589\n",
      "Iteration 211, loss = 0.30271480\n",
      "Iteration 212, loss = 0.30178616\n",
      "Iteration 213, loss = 0.30077912\n",
      "Iteration 214, loss = 0.29998252\n",
      "Iteration 215, loss = 0.29888151\n",
      "Iteration 216, loss = 0.29851158\n",
      "Iteration 217, loss = 0.29773112\n",
      "Iteration 218, loss = 0.29637986\n",
      "Iteration 219, loss = 0.29489723\n",
      "Iteration 220, loss = 0.29371778\n",
      "Iteration 221, loss = 0.29341448\n",
      "Iteration 222, loss = 0.29379585\n",
      "Iteration 223, loss = 0.29385425\n",
      "Iteration 224, loss = 0.29333802\n",
      "Iteration 225, loss = 0.29187780\n",
      "Iteration 226, loss = 0.28968103\n",
      "Iteration 227, loss = 0.28821283\n",
      "Iteration 228, loss = 0.28684375\n",
      "Iteration 229, loss = 0.28599603\n",
      "Iteration 230, loss = 0.28503137\n",
      "Iteration 231, loss = 0.28393314\n",
      "Iteration 232, loss = 0.28308525\n",
      "Iteration 233, loss = 0.28194303\n",
      "Iteration 234, loss = 0.28106447\n",
      "Iteration 235, loss = 0.28062959\n",
      "Iteration 236, loss = 0.28036265\n",
      "Iteration 237, loss = 0.27956514\n",
      "Iteration 238, loss = 0.27855510\n",
      "Iteration 239, loss = 0.27731061\n",
      "Iteration 240, loss = 0.27624895\n",
      "Iteration 241, loss = 0.27535304\n",
      "Iteration 242, loss = 0.27475054\n",
      "Iteration 243, loss = 0.27404968\n",
      "Iteration 244, loss = 0.27354322\n",
      "Iteration 245, loss = 0.27253434\n",
      "Iteration 246, loss = 0.27113086\n",
      "Iteration 247, loss = 0.27007427\n",
      "Iteration 248, loss = 0.26911174\n",
      "Iteration 249, loss = 0.26841157\n",
      "Iteration 250, loss = 0.26775278\n",
      "Iteration 251, loss = 0.26692457\n",
      "Iteration 252, loss = 0.26588443\n",
      "Iteration 253, loss = 0.26481910\n",
      "Iteration 254, loss = 0.26373069\n",
      "Iteration 255, loss = 0.26276209\n",
      "Iteration 256, loss = 0.26181440\n",
      "Iteration 257, loss = 0.26173063\n",
      "Iteration 258, loss = 0.26050646\n",
      "Iteration 259, loss = 0.25952738\n",
      "Iteration 260, loss = 0.25843292\n",
      "Iteration 261, loss = 0.25757688\n",
      "Iteration 262, loss = 0.25715499\n",
      "Iteration 263, loss = 0.25620340\n",
      "Iteration 264, loss = 0.25509678\n",
      "Iteration 265, loss = 0.25386515\n",
      "Iteration 266, loss = 0.25294767\n",
      "Iteration 267, loss = 0.25248447\n",
      "Iteration 268, loss = 0.25226069\n",
      "Iteration 269, loss = 0.25162032\n",
      "Iteration 270, loss = 0.25070989\n",
      "Iteration 271, loss = 0.24974255\n",
      "Iteration 272, loss = 0.24854619\n",
      "Iteration 273, loss = 0.24762242\n",
      "Iteration 274, loss = 0.24672021\n",
      "Iteration 275, loss = 0.24635927\n",
      "Iteration 276, loss = 0.24586502\n",
      "Iteration 277, loss = 0.24558633\n",
      "Iteration 278, loss = 0.24487638\n",
      "Iteration 279, loss = 0.24352604\n",
      "Iteration 280, loss = 0.24199091\n",
      "Iteration 281, loss = 0.24122859\n",
      "Iteration 282, loss = 0.24002786\n",
      "Iteration 283, loss = 0.23935800\n",
      "Iteration 284, loss = 0.23833305\n",
      "Iteration 285, loss = 0.23759981\n",
      "Iteration 286, loss = 0.23713030\n",
      "Iteration 287, loss = 0.23682803\n",
      "Iteration 288, loss = 0.23666087\n",
      "Iteration 289, loss = 0.23562594\n",
      "Iteration 290, loss = 0.23463873\n",
      "Iteration 291, loss = 0.23348830\n",
      "Iteration 292, loss = 0.23297748\n",
      "Iteration 293, loss = 0.23250457\n",
      "Iteration 294, loss = 0.23174869\n",
      "Iteration 295, loss = 0.23096906\n",
      "Iteration 296, loss = 0.22989451\n",
      "Iteration 297, loss = 0.22877564\n",
      "Iteration 298, loss = 0.22860642\n",
      "Iteration 299, loss = 0.22883872\n",
      "Iteration 300, loss = 0.22854344\n",
      "Iteration 301, loss = 0.22766100\n",
      "Iteration 302, loss = 0.22649501\n",
      "Iteration 303, loss = 0.22546391\n",
      "Iteration 304, loss = 0.22462082\n",
      "Iteration 305, loss = 0.22395346\n",
      "Iteration 306, loss = 0.22329512\n",
      "Iteration 307, loss = 0.22285296\n",
      "Iteration 308, loss = 0.22228180\n",
      "Iteration 309, loss = 0.22157140\n",
      "Iteration 310, loss = 0.22079243\n",
      "Iteration 311, loss = 0.21977764\n",
      "Iteration 312, loss = 0.21917719\n",
      "Iteration 313, loss = 0.21839546\n",
      "Iteration 314, loss = 0.21772399\n",
      "Iteration 315, loss = 0.21712298\n",
      "Iteration 316, loss = 0.21642999\n",
      "Iteration 317, loss = 0.21573385\n",
      "Iteration 318, loss = 0.21501405\n",
      "Iteration 319, loss = 0.21456880\n",
      "Iteration 320, loss = 0.21368371\n",
      "Iteration 321, loss = 0.21373183\n",
      "Iteration 322, loss = 0.21328542\n",
      "Iteration 323, loss = 0.21232419\n",
      "Iteration 324, loss = 0.21100300\n",
      "Iteration 325, loss = 0.21025289\n",
      "Iteration 326, loss = 0.21016664\n",
      "Iteration 327, loss = 0.21058582\n",
      "Iteration 328, loss = 0.21126730\n",
      "Iteration 329, loss = 0.21076324\n",
      "Iteration 330, loss = 0.20887765\n",
      "Iteration 331, loss = 0.20687239\n",
      "Iteration 332, loss = 0.20671750\n",
      "Iteration 333, loss = 0.20639148\n",
      "Iteration 334, loss = 0.20639466\n",
      "Iteration 335, loss = 0.20592339\n",
      "Iteration 336, loss = 0.20500106\n",
      "Iteration 337, loss = 0.20395617\n",
      "Iteration 338, loss = 0.20318724\n",
      "Iteration 339, loss = 0.20231171\n",
      "Iteration 340, loss = 0.20155663\n",
      "Iteration 341, loss = 0.20119109\n",
      "Iteration 342, loss = 0.20110099\n",
      "Iteration 343, loss = 0.20078349\n",
      "Iteration 344, loss = 0.20007791\n",
      "Iteration 345, loss = 0.19908515\n",
      "Iteration 346, loss = 0.19827969\n",
      "Iteration 347, loss = 0.19789756\n",
      "Iteration 348, loss = 0.19756529\n",
      "Iteration 349, loss = 0.19714249\n",
      "Iteration 350, loss = 0.19657185\n",
      "Iteration 351, loss = 0.19580560\n",
      "Iteration 352, loss = 0.19536467\n",
      "Iteration 353, loss = 0.19457041\n",
      "Iteration 354, loss = 0.19401645\n",
      "Iteration 355, loss = 0.19350750\n",
      "Iteration 356, loss = 0.19302663\n",
      "Iteration 357, loss = 0.19233222\n",
      "Iteration 358, loss = 0.19178808\n",
      "Iteration 359, loss = 0.19117678\n",
      "Iteration 360, loss = 0.19072596\n",
      "Iteration 361, loss = 0.19010248\n",
      "Iteration 362, loss = 0.18971670\n",
      "Iteration 363, loss = 0.18906797\n",
      "Iteration 364, loss = 0.18871854\n",
      "Iteration 365, loss = 0.18818347\n",
      "Iteration 366, loss = 0.18761760\n",
      "Iteration 367, loss = 0.18698413\n",
      "Iteration 368, loss = 0.18641788\n",
      "Iteration 369, loss = 0.18597184\n",
      "Iteration 370, loss = 0.18529799\n",
      "Iteration 371, loss = 0.18478279\n",
      "Iteration 372, loss = 0.18428841\n",
      "Iteration 373, loss = 0.18372885\n",
      "Iteration 374, loss = 0.18322472\n",
      "Iteration 375, loss = 0.18268620\n",
      "Iteration 376, loss = 0.18208103\n",
      "Iteration 377, loss = 0.18161733\n",
      "Iteration 378, loss = 0.18101341\n",
      "Iteration 379, loss = 0.18054795\n",
      "Iteration 380, loss = 0.18001041\n",
      "Iteration 381, loss = 0.17947306\n",
      "Iteration 382, loss = 0.17883882\n",
      "Iteration 383, loss = 0.17847103\n",
      "Iteration 384, loss = 0.17793780\n",
      "Iteration 385, loss = 0.17738498\n",
      "Iteration 386, loss = 0.17688929\n",
      "Iteration 387, loss = 0.17636730\n",
      "Iteration 388, loss = 0.17638334\n",
      "Iteration 389, loss = 0.17643023\n",
      "Iteration 390, loss = 0.17617466\n",
      "Iteration 391, loss = 0.17613633\n",
      "Iteration 392, loss = 0.17495389\n",
      "Iteration 393, loss = 0.17358268\n",
      "Iteration 394, loss = 0.17357247\n",
      "Iteration 395, loss = 0.17406294\n",
      "Iteration 396, loss = 0.17511499\n",
      "Iteration 397, loss = 0.17599274\n",
      "Iteration 398, loss = 0.17589439\n",
      "Iteration 399, loss = 0.17491927\n",
      "Iteration 400, loss = 0.17243075\n",
      "Iteration 401, loss = 0.17048555\n",
      "Iteration 402, loss = 0.17041147\n",
      "Iteration 403, loss = 0.17093862\n",
      "Iteration 404, loss = 0.17187902\n",
      "Iteration 405, loss = 0.17158447\n",
      "Iteration 406, loss = 0.17005043\n",
      "Iteration 407, loss = 0.16862924\n",
      "Iteration 408, loss = 0.16760437\n",
      "Iteration 409, loss = 0.16701538\n",
      "Iteration 410, loss = 0.16642090\n",
      "Iteration 411, loss = 0.16568702\n",
      "Iteration 412, loss = 0.16542930\n",
      "Iteration 413, loss = 0.16509474\n",
      "Iteration 414, loss = 0.16499887\n",
      "Iteration 415, loss = 0.16444630\n",
      "Iteration 416, loss = 0.16385068\n",
      "Iteration 417, loss = 0.16308443\n",
      "Iteration 418, loss = 0.16252979\n",
      "Iteration 419, loss = 0.16224798\n",
      "Iteration 420, loss = 0.16198008\n",
      "Iteration 421, loss = 0.16198702\n",
      "Iteration 422, loss = 0.16193327\n",
      "Iteration 423, loss = 0.16160739\n",
      "Iteration 424, loss = 0.16065330\n",
      "Iteration 425, loss = 0.15947130\n",
      "Iteration 426, loss = 0.15904337\n",
      "Iteration 427, loss = 0.15928273\n",
      "Iteration 428, loss = 0.15971243\n",
      "Iteration 429, loss = 0.15993120\n",
      "Iteration 430, loss = 0.15974933\n",
      "Iteration 431, loss = 0.15877383\n",
      "Iteration 432, loss = 0.15725499\n",
      "Iteration 433, loss = 0.15639175\n",
      "Iteration 434, loss = 0.15603908\n",
      "Iteration 435, loss = 0.15644605\n",
      "Iteration 436, loss = 0.15666349\n",
      "Iteration 437, loss = 0.15661529\n",
      "Iteration 438, loss = 0.15586840\n",
      "Iteration 439, loss = 0.15452521\n",
      "Iteration 440, loss = 0.15361697\n",
      "Iteration 441, loss = 0.15373172\n",
      "Iteration 442, loss = 0.15399856\n",
      "Iteration 443, loss = 0.15426284\n",
      "Iteration 444, loss = 0.15408967\n",
      "Iteration 445, loss = 0.15325194\n",
      "Iteration 446, loss = 0.15204253\n",
      "Iteration 447, loss = 0.15111196\n",
      "Iteration 448, loss = 0.15064484\n",
      "Iteration 449, loss = 0.15043851\n",
      "Iteration 450, loss = 0.15079650\n",
      "Iteration 451, loss = 0.15060075\n",
      "Iteration 452, loss = 0.14991315\n",
      "Iteration 453, loss = 0.14922314\n",
      "Iteration 454, loss = 0.14852526\n",
      "Iteration 455, loss = 0.14790933\n",
      "Iteration 456, loss = 0.14732902\n",
      "Iteration 457, loss = 0.14696886\n",
      "Iteration 458, loss = 0.14646532\n",
      "Iteration 459, loss = 0.14579799\n",
      "Iteration 460, loss = 0.14532753\n",
      "Iteration 461, loss = 0.14549364\n",
      "Iteration 462, loss = 0.14582361\n",
      "Iteration 463, loss = 0.14585732\n",
      "Iteration 464, loss = 0.14578247\n",
      "Iteration 465, loss = 0.14507709\n",
      "Iteration 466, loss = 0.14408129\n",
      "Iteration 467, loss = 0.14318078\n",
      "Iteration 468, loss = 0.14307680\n",
      "Iteration 469, loss = 0.14283906\n",
      "Iteration 470, loss = 0.14242411\n",
      "Iteration 471, loss = 0.14192742\n",
      "Iteration 472, loss = 0.14148396\n",
      "Iteration 473, loss = 0.14094001\n",
      "Iteration 474, loss = 0.14052945\n",
      "Iteration 475, loss = 0.14034145\n",
      "Iteration 476, loss = 0.14030774\n",
      "Iteration 477, loss = 0.14064894\n",
      "Iteration 478, loss = 0.14043400\n",
      "Iteration 479, loss = 0.13973869\n",
      "Iteration 480, loss = 0.13914970\n",
      "Iteration 481, loss = 0.13874100\n",
      "Iteration 482, loss = 0.13855459\n",
      "Iteration 483, loss = 0.13827286\n",
      "Iteration 484, loss = 0.13792821\n",
      "Iteration 485, loss = 0.13739390\n",
      "Iteration 486, loss = 0.13711745\n",
      "Iteration 487, loss = 0.13700884\n",
      "Iteration 488, loss = 0.13678074\n",
      "Iteration 489, loss = 0.13615930\n",
      "Iteration 490, loss = 0.13552414\n",
      "Iteration 491, loss = 0.13514398\n",
      "Iteration 492, loss = 0.13461668\n",
      "Iteration 493, loss = 0.13420566\n",
      "Iteration 494, loss = 0.13374760\n",
      "Iteration 495, loss = 0.13365208\n",
      "Iteration 496, loss = 0.13329734\n",
      "Iteration 497, loss = 0.13277286\n",
      "Iteration 498, loss = 0.13263281\n",
      "Iteration 499, loss = 0.13243080\n",
      "Iteration 500, loss = 0.13232571\n",
      "Iteration 501, loss = 0.13209652\n",
      "Iteration 502, loss = 0.13189861\n",
      "Iteration 503, loss = 0.13131135\n",
      "Iteration 504, loss = 0.13064025\n",
      "Iteration 505, loss = 0.13060457\n",
      "Iteration 506, loss = 0.13028500\n",
      "Iteration 507, loss = 0.13023180\n",
      "Iteration 508, loss = 0.13037524\n",
      "Iteration 509, loss = 0.13033884\n",
      "Iteration 510, loss = 0.13030545\n",
      "Iteration 511, loss = 0.12997999\n",
      "Iteration 512, loss = 0.12947091\n",
      "Iteration 513, loss = 0.12901466\n",
      "Iteration 514, loss = 0.12886055\n",
      "Iteration 515, loss = 0.12856691\n",
      "Iteration 516, loss = 0.12802337\n",
      "Iteration 517, loss = 0.12742848\n",
      "Iteration 518, loss = 0.12701798\n",
      "Iteration 519, loss = 0.12657808\n",
      "Iteration 520, loss = 0.12610457\n",
      "Iteration 521, loss = 0.12565741\n",
      "Iteration 522, loss = 0.12552421\n",
      "Iteration 523, loss = 0.12510890\n",
      "Iteration 524, loss = 0.12474469\n",
      "Iteration 525, loss = 0.12450829\n",
      "Iteration 526, loss = 0.12417621\n",
      "Iteration 527, loss = 0.12392066\n",
      "Iteration 528, loss = 0.12381506\n",
      "Iteration 529, loss = 0.12408533\n",
      "Iteration 530, loss = 0.12446489\n",
      "Iteration 531, loss = 0.12408769\n",
      "Iteration 532, loss = 0.12344588\n",
      "Iteration 533, loss = 0.12288179\n",
      "Iteration 534, loss = 0.12220756\n",
      "Iteration 535, loss = 0.12185794\n",
      "Iteration 536, loss = 0.12155203\n",
      "Iteration 537, loss = 0.12139019\n",
      "Iteration 538, loss = 0.12100514\n",
      "Iteration 539, loss = 0.12052608\n",
      "Iteration 540, loss = 0.12018597\n",
      "Iteration 541, loss = 0.11988697\n",
      "Iteration 542, loss = 0.11951284\n",
      "Iteration 543, loss = 0.11911496\n",
      "Iteration 544, loss = 0.11884608\n",
      "Iteration 545, loss = 0.11850360\n",
      "Iteration 546, loss = 0.11834886\n",
      "Iteration 547, loss = 0.11800900\n",
      "Iteration 548, loss = 0.11795227\n",
      "Iteration 549, loss = 0.11823221\n",
      "Iteration 550, loss = 0.11860888\n",
      "Iteration 551, loss = 0.11785969\n",
      "Iteration 552, loss = 0.11713300\n",
      "Iteration 553, loss = 0.11646542\n",
      "Iteration 554, loss = 0.11664942\n",
      "Iteration 555, loss = 0.11629924\n",
      "Iteration 556, loss = 0.11597340\n",
      "Iteration 557, loss = 0.11552992\n",
      "Iteration 558, loss = 0.11534776\n",
      "Iteration 559, loss = 0.11510125\n",
      "Iteration 560, loss = 0.11480832\n",
      "Iteration 561, loss = 0.11453896\n",
      "Iteration 562, loss = 0.11446253\n",
      "Iteration 563, loss = 0.11429892\n",
      "Iteration 564, loss = 0.11428520\n",
      "Iteration 565, loss = 0.11416634\n",
      "Iteration 566, loss = 0.11390231\n",
      "Iteration 567, loss = 0.11348713\n",
      "Iteration 568, loss = 0.11302990\n",
      "Iteration 569, loss = 0.11265481\n",
      "Iteration 570, loss = 0.11254822\n",
      "Iteration 571, loss = 0.11227980\n",
      "Iteration 572, loss = 0.11188567\n",
      "Iteration 573, loss = 0.11189672\n",
      "Iteration 574, loss = 0.11142194\n",
      "Iteration 575, loss = 0.11093104\n",
      "Iteration 576, loss = 0.11083257\n",
      "Iteration 577, loss = 0.11159732\n",
      "Iteration 578, loss = 0.11200640\n",
      "Iteration 579, loss = 0.11161822\n",
      "Iteration 580, loss = 0.11074425\n",
      "Iteration 581, loss = 0.11026406\n",
      "Iteration 582, loss = 0.10968215\n",
      "Iteration 583, loss = 0.10928863\n",
      "Iteration 584, loss = 0.10925852\n",
      "Iteration 585, loss = 0.10854400\n",
      "Iteration 586, loss = 0.10856518\n",
      "Iteration 587, loss = 0.10842202\n",
      "Iteration 588, loss = 0.10832120\n",
      "Iteration 589, loss = 0.10790286\n",
      "Iteration 590, loss = 0.10740049\n",
      "Iteration 591, loss = 0.10738541\n",
      "Iteration 592, loss = 0.10677512\n",
      "Iteration 593, loss = 0.10660069\n",
      "Iteration 594, loss = 0.10647749\n",
      "Iteration 595, loss = 0.10589566\n",
      "Iteration 596, loss = 0.10568261\n",
      "Iteration 597, loss = 0.10580622\n",
      "Iteration 598, loss = 0.10713674\n",
      "Iteration 599, loss = 0.10790898\n",
      "Iteration 600, loss = 0.10779920\n",
      "Iteration 601, loss = 0.10716078\n",
      "Iteration 602, loss = 0.10630628\n",
      "Iteration 603, loss = 0.10546054\n",
      "Iteration 604, loss = 0.10483074\n",
      "Iteration 605, loss = 0.10448504\n",
      "Iteration 606, loss = 0.10439567\n",
      "Iteration 607, loss = 0.10455653\n",
      "Iteration 608, loss = 0.10420823\n",
      "Iteration 609, loss = 0.10381775\n",
      "Iteration 610, loss = 0.10332805\n",
      "Iteration 611, loss = 0.10315480\n",
      "Iteration 612, loss = 0.10270417\n",
      "Iteration 613, loss = 0.10261110\n",
      "Iteration 614, loss = 0.10250010\n",
      "Iteration 615, loss = 0.10210611\n",
      "Iteration 616, loss = 0.10161266\n",
      "Iteration 617, loss = 0.10133987\n",
      "Iteration 618, loss = 0.10215657\n",
      "Iteration 619, loss = 0.10286587\n",
      "Iteration 620, loss = 0.10331075\n",
      "Iteration 621, loss = 0.10304136\n",
      "Iteration 622, loss = 0.10194154\n",
      "Iteration 623, loss = 0.10075642\n",
      "Iteration 624, loss = 0.10018389\n",
      "Iteration 625, loss = 0.10019307\n",
      "Iteration 626, loss = 0.10079559\n",
      "Iteration 627, loss = 0.10100840\n",
      "Iteration 628, loss = 0.10088308\n",
      "Iteration 629, loss = 0.10041451\n",
      "Iteration 630, loss = 0.10017118\n",
      "Iteration 631, loss = 0.09966326\n",
      "Iteration 632, loss = 0.09905234\n",
      "Iteration 633, loss = 0.09855442\n",
      "Iteration 634, loss = 0.09818974\n",
      "Iteration 635, loss = 0.09780876\n",
      "Iteration 636, loss = 0.09757100\n",
      "Iteration 637, loss = 0.09746737\n",
      "Iteration 638, loss = 0.09732412\n",
      "Iteration 639, loss = 0.09722261\n",
      "Iteration 640, loss = 0.09739610\n",
      "Iteration 641, loss = 0.09692211\n",
      "Iteration 642, loss = 0.09661709\n",
      "Iteration 643, loss = 0.09618769\n",
      "Iteration 644, loss = 0.09592256\n",
      "Iteration 645, loss = 0.09562810\n",
      "Iteration 646, loss = 0.09540661\n",
      "Iteration 647, loss = 0.09515058\n",
      "Iteration 648, loss = 0.09502404\n",
      "Iteration 649, loss = 0.09498411\n",
      "Iteration 650, loss = 0.09504520\n",
      "Iteration 651, loss = 0.09493913\n",
      "Iteration 652, loss = 0.09452152\n",
      "Iteration 653, loss = 0.09447709\n",
      "Iteration 654, loss = 0.09428137\n",
      "Iteration 655, loss = 0.09415301\n",
      "Iteration 656, loss = 0.09391222\n",
      "Iteration 657, loss = 0.09399194\n",
      "Iteration 658, loss = 0.09397475\n",
      "Iteration 659, loss = 0.09403237\n",
      "Iteration 660, loss = 0.09392232\n",
      "Iteration 661, loss = 0.09354405\n",
      "Iteration 662, loss = 0.09318956\n",
      "Iteration 663, loss = 0.09305349\n",
      "Iteration 664, loss = 0.09290523\n",
      "Iteration 665, loss = 0.09279668\n",
      "Iteration 666, loss = 0.09299046\n",
      "Iteration 667, loss = 0.09249673\n",
      "Iteration 668, loss = 0.09198290\n",
      "Iteration 669, loss = 0.09179824\n",
      "Iteration 670, loss = 0.09157104\n",
      "Iteration 671, loss = 0.09159181\n",
      "Iteration 672, loss = 0.09124860\n",
      "Iteration 673, loss = 0.09096077\n",
      "Iteration 674, loss = 0.09074276\n",
      "Iteration 675, loss = 0.09050276\n",
      "Iteration 676, loss = 0.09036496\n",
      "Iteration 677, loss = 0.09012648\n",
      "Iteration 678, loss = 0.08993801\n",
      "Iteration 679, loss = 0.08991410\n",
      "Iteration 680, loss = 0.08970949\n",
      "Iteration 681, loss = 0.08956671\n",
      "Iteration 682, loss = 0.08955766\n",
      "Iteration 683, loss = 0.08958548\n",
      "Iteration 684, loss = 0.08946048\n",
      "Iteration 685, loss = 0.08933831\n",
      "Iteration 686, loss = 0.08910190\n",
      "Iteration 687, loss = 0.08881990\n",
      "Iteration 688, loss = 0.08848365\n",
      "Iteration 689, loss = 0.08811432\n",
      "Iteration 690, loss = 0.08774645\n",
      "Iteration 691, loss = 0.08802359\n",
      "Iteration 692, loss = 0.08846305\n",
      "Iteration 693, loss = 0.08893412\n",
      "Iteration 694, loss = 0.08891812\n",
      "Iteration 695, loss = 0.08867471\n",
      "Iteration 696, loss = 0.08854208\n",
      "Iteration 697, loss = 0.08850998\n",
      "Iteration 698, loss = 0.08826999\n",
      "Iteration 699, loss = 0.08761268\n",
      "Iteration 700, loss = 0.08699384\n",
      "Iteration 701, loss = 0.08667374\n",
      "Iteration 702, loss = 0.08647278\n",
      "Iteration 703, loss = 0.08615157\n",
      "Iteration 704, loss = 0.08584646\n",
      "Iteration 705, loss = 0.08557199\n",
      "Iteration 706, loss = 0.08543613\n",
      "Iteration 707, loss = 0.08518988\n",
      "Iteration 708, loss = 0.08513727\n",
      "Iteration 709, loss = 0.08488716\n",
      "Iteration 710, loss = 0.08491303\n",
      "Iteration 711, loss = 0.08471019\n",
      "Iteration 712, loss = 0.08446750\n",
      "Iteration 713, loss = 0.08441537\n",
      "Iteration 714, loss = 0.08429227\n",
      "Iteration 715, loss = 0.08417310\n",
      "Iteration 716, loss = 0.08393741\n",
      "Iteration 717, loss = 0.08385134\n",
      "Iteration 718, loss = 0.08382158\n",
      "Iteration 719, loss = 0.08376241\n",
      "Iteration 720, loss = 0.08409543\n",
      "Iteration 721, loss = 0.08468090\n",
      "Iteration 722, loss = 0.08492857\n",
      "Iteration 723, loss = 0.08457518\n",
      "Iteration 724, loss = 0.08403574\n",
      "Iteration 725, loss = 0.08311781\n",
      "Iteration 726, loss = 0.08248494\n",
      "Iteration 727, loss = 0.08233226\n",
      "Iteration 728, loss = 0.08243779\n",
      "Iteration 729, loss = 0.08249443\n",
      "Iteration 730, loss = 0.08271888\n",
      "Iteration 731, loss = 0.08273461\n",
      "Iteration 732, loss = 0.08197521\n",
      "Iteration 733, loss = 0.08130550\n",
      "Iteration 734, loss = 0.08128069\n",
      "Iteration 735, loss = 0.08237875\n",
      "Iteration 736, loss = 0.08253776\n",
      "Iteration 737, loss = 0.08201142\n",
      "Iteration 738, loss = 0.08124438\n",
      "Iteration 739, loss = 0.08073466\n",
      "Iteration 740, loss = 0.08035616\n",
      "Iteration 741, loss = 0.08052435\n",
      "Iteration 742, loss = 0.08044920\n",
      "Iteration 743, loss = 0.08016580\n",
      "Iteration 744, loss = 0.07993958\n",
      "Iteration 745, loss = 0.07970734\n",
      "Iteration 746, loss = 0.07958036\n",
      "Iteration 747, loss = 0.07939105\n",
      "Iteration 748, loss = 0.07933381\n",
      "Iteration 749, loss = 0.07926616\n",
      "Iteration 750, loss = 0.07922632\n",
      "Iteration 751, loss = 0.07914182\n",
      "Iteration 752, loss = 0.07908450\n",
      "Iteration 753, loss = 0.07910430\n",
      "Iteration 754, loss = 0.07885367\n",
      "Iteration 755, loss = 0.07861211\n",
      "Iteration 756, loss = 0.07838623\n",
      "Iteration 757, loss = 0.07822682\n",
      "Iteration 758, loss = 0.07814118\n",
      "Iteration 759, loss = 0.07830735\n",
      "Iteration 760, loss = 0.07820946\n",
      "Iteration 761, loss = 0.07775692\n",
      "Iteration 762, loss = 0.07754631\n",
      "Iteration 763, loss = 0.07729739\n",
      "Iteration 764, loss = 0.07711305\n",
      "Iteration 765, loss = 0.07680313\n",
      "Iteration 766, loss = 0.07739808\n",
      "Iteration 767, loss = 0.07802501\n",
      "Iteration 768, loss = 0.07941574\n",
      "Iteration 769, loss = 0.08016882\n",
      "Iteration 770, loss = 0.08028556\n",
      "Iteration 771, loss = 0.08056672\n",
      "Iteration 772, loss = 0.08041767\n",
      "Iteration 773, loss = 0.07871376\n",
      "Iteration 774, loss = 0.07695838\n",
      "Iteration 775, loss = 0.07662587\n",
      "Iteration 776, loss = 0.07723917\n",
      "Iteration 777, loss = 0.07760851\n",
      "Iteration 778, loss = 0.07749474\n",
      "Iteration 779, loss = 0.07712274\n",
      "Iteration 780, loss = 0.07662810\n",
      "Iteration 781, loss = 0.07605685\n",
      "Iteration 782, loss = 0.07569754\n",
      "Iteration 783, loss = 0.07536284\n",
      "Iteration 784, loss = 0.07532156\n",
      "Iteration 785, loss = 0.07526055\n",
      "Iteration 786, loss = 0.07522737\n",
      "Iteration 787, loss = 0.07505156\n",
      "Iteration 788, loss = 0.07466784\n",
      "Iteration 789, loss = 0.07441513\n",
      "Iteration 790, loss = 0.07394896\n",
      "Iteration 791, loss = 0.07358760\n",
      "Iteration 792, loss = 0.07357359\n",
      "Iteration 793, loss = 0.07343230\n",
      "Iteration 794, loss = 0.07336853\n",
      "Iteration 795, loss = 0.07319854\n",
      "Iteration 796, loss = 0.07310696\n",
      "Iteration 797, loss = 0.07305085\n",
      "Iteration 798, loss = 0.07293696\n",
      "Iteration 799, loss = 0.07276034\n",
      "Iteration 800, loss = 0.07257415\n",
      "Iteration 801, loss = 0.07243060\n",
      "Iteration 802, loss = 0.07230116\n",
      "Iteration 803, loss = 0.07213226\n",
      "Iteration 804, loss = 0.07215697\n",
      "Iteration 805, loss = 0.07231034\n",
      "Iteration 806, loss = 0.07234012\n",
      "Iteration 807, loss = 0.07216596\n",
      "Iteration 808, loss = 0.07181898\n",
      "Iteration 809, loss = 0.07146402\n",
      "Iteration 810, loss = 0.07131763\n",
      "Iteration 811, loss = 0.07112341\n",
      "Iteration 812, loss = 0.07138505\n",
      "Iteration 813, loss = 0.07147928\n",
      "Iteration 814, loss = 0.07152058\n",
      "Iteration 815, loss = 0.07148381\n",
      "Iteration 816, loss = 0.07100613\n",
      "Iteration 817, loss = 0.07080144\n",
      "Iteration 818, loss = 0.07068345\n",
      "Iteration 819, loss = 0.07058077\n",
      "Iteration 820, loss = 0.07029477\n",
      "Iteration 821, loss = 0.06999053\n",
      "Iteration 822, loss = 0.06998194\n",
      "Iteration 823, loss = 0.06994136\n",
      "Iteration 824, loss = 0.06991048\n",
      "Iteration 825, loss = 0.07004336\n",
      "Iteration 826, loss = 0.07011077\n",
      "Iteration 827, loss = 0.07008640\n",
      "Iteration 828, loss = 0.06995238\n",
      "Iteration 829, loss = 0.06988280\n",
      "Iteration 830, loss = 0.06977486\n",
      "Iteration 831, loss = 0.06946858\n",
      "Iteration 832, loss = 0.06924451\n",
      "Iteration 833, loss = 0.06878804\n",
      "Iteration 834, loss = 0.06891006\n",
      "Iteration 835, loss = 0.06908710\n",
      "Iteration 836, loss = 0.06935351\n",
      "Iteration 837, loss = 0.06992629\n",
      "Iteration 838, loss = 0.07048762\n",
      "Iteration 839, loss = 0.07021302\n",
      "Iteration 840, loss = 0.06929137\n",
      "Iteration 841, loss = 0.06856966\n",
      "Iteration 842, loss = 0.06836393\n",
      "Iteration 843, loss = 0.06846611\n",
      "Iteration 844, loss = 0.06894638\n",
      "Iteration 845, loss = 0.06881915\n",
      "Iteration 846, loss = 0.06847259\n",
      "Iteration 847, loss = 0.06809172\n",
      "Iteration 848, loss = 0.06747235\n",
      "Iteration 849, loss = 0.06715328\n",
      "Iteration 850, loss = 0.06696356\n",
      "Iteration 851, loss = 0.06677968\n",
      "Iteration 852, loss = 0.06668547\n",
      "Iteration 853, loss = 0.06686749\n",
      "Iteration 854, loss = 0.06675952\n",
      "Iteration 855, loss = 0.06652674\n",
      "Iteration 856, loss = 0.06641270\n",
      "Iteration 857, loss = 0.06636872\n",
      "Iteration 858, loss = 0.06676220\n",
      "Iteration 859, loss = 0.06682400\n",
      "Iteration 860, loss = 0.06643598\n",
      "Iteration 861, loss = 0.06629154\n",
      "Iteration 862, loss = 0.06594190\n",
      "Iteration 863, loss = 0.06588099\n",
      "Iteration 864, loss = 0.06580412\n",
      "Iteration 865, loss = 0.06585528\n",
      "Iteration 866, loss = 0.06574705\n",
      "Iteration 867, loss = 0.06580007\n",
      "Iteration 868, loss = 0.06589850\n",
      "Iteration 869, loss = 0.06650015\n",
      "Iteration 870, loss = 0.06614996\n",
      "Iteration 871, loss = 0.06550191\n",
      "Iteration 872, loss = 0.06493503\n",
      "Iteration 873, loss = 0.06455457\n",
      "Iteration 874, loss = 0.06500208\n",
      "Iteration 875, loss = 0.06542044\n",
      "Iteration 876, loss = 0.06540797\n",
      "Iteration 877, loss = 0.06477363\n",
      "Iteration 878, loss = 0.06400820\n",
      "Iteration 879, loss = 0.06395229\n",
      "Iteration 880, loss = 0.06466197\n",
      "Iteration 881, loss = 0.06487867\n",
      "Iteration 882, loss = 0.06494327\n",
      "Iteration 883, loss = 0.06477990\n",
      "Iteration 884, loss = 0.06429134\n",
      "Iteration 885, loss = 0.06377775\n",
      "Iteration 886, loss = 0.06386637\n",
      "Iteration 887, loss = 0.06344822\n",
      "Iteration 888, loss = 0.06318159\n",
      "Iteration 889, loss = 0.06306964\n",
      "Iteration 890, loss = 0.06293443\n",
      "Iteration 891, loss = 0.06284322\n",
      "Iteration 892, loss = 0.06276202\n",
      "Iteration 893, loss = 0.06268040\n",
      "Iteration 894, loss = 0.06256054\n",
      "Iteration 895, loss = 0.06264096\n",
      "Iteration 896, loss = 0.06268566\n",
      "Iteration 897, loss = 0.06296126\n",
      "Iteration 898, loss = 0.06324288\n",
      "Iteration 899, loss = 0.06295590\n",
      "Iteration 900, loss = 0.06264301\n",
      "Iteration 901, loss = 0.06234141\n",
      "Iteration 902, loss = 0.06224927\n",
      "Iteration 903, loss = 0.06221198\n",
      "Iteration 904, loss = 0.06188900\n",
      "Iteration 905, loss = 0.06192792\n",
      "Iteration 906, loss = 0.06177795\n",
      "Iteration 907, loss = 0.06154549\n",
      "Iteration 908, loss = 0.06145157\n",
      "Iteration 909, loss = 0.06170482\n",
      "Iteration 910, loss = 0.06168856\n",
      "Iteration 911, loss = 0.06158534\n",
      "Iteration 912, loss = 0.06141403\n",
      "Iteration 913, loss = 0.06119858\n",
      "Iteration 914, loss = 0.06109574\n",
      "Iteration 915, loss = 0.06107060\n",
      "Iteration 916, loss = 0.06094310\n",
      "Iteration 917, loss = 0.06069559\n",
      "Iteration 918, loss = 0.06055268\n",
      "Iteration 919, loss = 0.06072933\n",
      "Iteration 920, loss = 0.06035256\n",
      "Iteration 921, loss = 0.06023510\n",
      "Iteration 922, loss = 0.06024978\n",
      "Iteration 923, loss = 0.06044601\n",
      "Iteration 924, loss = 0.06074574\n",
      "Iteration 925, loss = 0.06097774\n",
      "Iteration 926, loss = 0.06096429\n",
      "Iteration 927, loss = 0.06073536\n",
      "Iteration 928, loss = 0.06053063\n",
      "Iteration 929, loss = 0.06015834\n",
      "Iteration 930, loss = 0.05981954\n",
      "Iteration 931, loss = 0.05966934\n",
      "Iteration 932, loss = 0.05942036\n",
      "Iteration 933, loss = 0.05942476\n",
      "Iteration 934, loss = 0.05922986\n",
      "Iteration 935, loss = 0.05909381\n",
      "Iteration 936, loss = 0.05890968\n",
      "Iteration 937, loss = 0.05879332\n",
      "Iteration 938, loss = 0.05874410\n",
      "Iteration 939, loss = 0.05877296\n",
      "Iteration 940, loss = 0.05894023\n",
      "Iteration 941, loss = 0.05898278\n",
      "Iteration 942, loss = 0.05893563\n",
      "Iteration 943, loss = 0.05877546\n",
      "Iteration 944, loss = 0.05861105\n",
      "Iteration 945, loss = 0.05826483\n",
      "Iteration 946, loss = 0.05811400\n",
      "Iteration 947, loss = 0.05855128\n",
      "Iteration 948, loss = 0.05880216\n",
      "Iteration 949, loss = 0.05885984\n",
      "Iteration 950, loss = 0.05864626\n",
      "Iteration 951, loss = 0.05826817\n",
      "Iteration 952, loss = 0.05811227\n",
      "Iteration 953, loss = 0.05769515\n",
      "Iteration 954, loss = 0.05759936\n",
      "Iteration 955, loss = 0.05760757\n",
      "Iteration 956, loss = 0.05762971\n",
      "Iteration 957, loss = 0.05789458\n",
      "Iteration 958, loss = 0.05768825\n",
      "Iteration 959, loss = 0.05746976\n",
      "Iteration 960, loss = 0.05725989\n",
      "Iteration 961, loss = 0.05709511\n",
      "Iteration 962, loss = 0.05705679\n",
      "Iteration 963, loss = 0.05732595\n",
      "Iteration 964, loss = 0.05773238\n",
      "Iteration 965, loss = 0.05787004\n",
      "Iteration 966, loss = 0.05767155\n",
      "Iteration 967, loss = 0.05730245\n",
      "Iteration 968, loss = 0.05718232\n",
      "Iteration 969, loss = 0.05705246\n",
      "Iteration 970, loss = 0.05691952\n",
      "Iteration 971, loss = 0.05686276\n",
      "Iteration 972, loss = 0.05663841\n",
      "Iteration 973, loss = 0.05672469\n",
      "Iteration 974, loss = 0.05689803\n",
      "Iteration 975, loss = 0.05717481\n",
      "Iteration 976, loss = 0.05737515\n",
      "Iteration 977, loss = 0.05709230\n",
      "Iteration 978, loss = 0.05656433\n",
      "Iteration 979, loss = 0.05606291\n",
      "Iteration 980, loss = 0.05580362\n",
      "Iteration 981, loss = 0.05589213\n",
      "Iteration 982, loss = 0.05569330\n",
      "Iteration 983, loss = 0.05534376\n",
      "Iteration 984, loss = 0.05535682\n",
      "Iteration 985, loss = 0.05546696\n",
      "Iteration 986, loss = 0.05585710\n",
      "Iteration 987, loss = 0.05581219\n",
      "Iteration 988, loss = 0.05571714\n",
      "Iteration 989, loss = 0.05583364\n",
      "Iteration 990, loss = 0.05563893\n",
      "Iteration 991, loss = 0.05565393\n",
      "Iteration 992, loss = 0.05552241\n",
      "Iteration 993, loss = 0.05535894\n",
      "Iteration 994, loss = 0.05505375\n",
      "Iteration 995, loss = 0.05483624\n",
      "Iteration 996, loss = 0.05459598\n",
      "Iteration 997, loss = 0.05452261\n",
      "Iteration 998, loss = 0.05446312\n",
      "Iteration 999, loss = 0.05433427\n",
      "Iteration 1000, loss = 0.05462610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.62105204\n",
      "Iteration 2, loss = 0.61925479\n",
      "Iteration 3, loss = 0.61776699\n",
      "Iteration 4, loss = 0.61628189\n",
      "Iteration 5, loss = 0.61499463\n",
      "Iteration 6, loss = 0.61379528\n",
      "Iteration 7, loss = 0.61264766\n",
      "Iteration 8, loss = 0.61154545\n",
      "Iteration 9, loss = 0.61041128\n",
      "Iteration 10, loss = 0.60935764\n",
      "Iteration 11, loss = 0.60839585\n",
      "Iteration 12, loss = 0.60732514\n",
      "Iteration 13, loss = 0.60644290\n",
      "Iteration 14, loss = 0.60549030\n",
      "Iteration 15, loss = 0.60465721\n",
      "Iteration 16, loss = 0.60373929\n",
      "Iteration 17, loss = 0.60289879\n",
      "Iteration 18, loss = 0.60203130\n",
      "Iteration 19, loss = 0.60115452\n",
      "Iteration 20, loss = 0.60031214\n",
      "Iteration 21, loss = 0.59945787\n",
      "Iteration 22, loss = 0.59856111\n",
      "Iteration 23, loss = 0.59772849\n",
      "Iteration 24, loss = 0.59682958\n",
      "Iteration 25, loss = 0.59596934\n",
      "Iteration 26, loss = 0.59508879\n",
      "Iteration 27, loss = 0.59427200\n",
      "Iteration 28, loss = 0.59338768\n",
      "Iteration 29, loss = 0.59255982\n",
      "Iteration 30, loss = 0.59174529\n",
      "Iteration 31, loss = 0.59086808\n",
      "Iteration 32, loss = 0.59001021\n",
      "Iteration 33, loss = 0.58910761\n",
      "Iteration 34, loss = 0.58829878\n",
      "Iteration 35, loss = 0.58743365\n",
      "Iteration 36, loss = 0.58652639\n",
      "Iteration 37, loss = 0.58573722\n",
      "Iteration 38, loss = 0.58493123\n",
      "Iteration 39, loss = 0.58406486\n",
      "Iteration 40, loss = 0.58332803\n",
      "Iteration 41, loss = 0.58253253\n",
      "Iteration 42, loss = 0.58173306\n",
      "Iteration 43, loss = 0.58096521\n",
      "Iteration 44, loss = 0.58007151\n",
      "Iteration 45, loss = 0.57929685\n",
      "Iteration 46, loss = 0.57850085\n",
      "Iteration 47, loss = 0.57773449\n",
      "Iteration 48, loss = 0.57693393\n",
      "Iteration 49, loss = 0.57622486\n",
      "Iteration 50, loss = 0.57549863\n",
      "Iteration 51, loss = 0.57475806\n",
      "Iteration 52, loss = 0.57412233\n",
      "Iteration 53, loss = 0.57337447\n",
      "Iteration 54, loss = 0.57271107\n",
      "Iteration 55, loss = 0.57197034\n",
      "Iteration 56, loss = 0.57125393\n",
      "Iteration 57, loss = 0.57054584\n",
      "Iteration 58, loss = 0.56981715\n",
      "Iteration 59, loss = 0.56906403\n",
      "Iteration 60, loss = 0.56828831\n",
      "Iteration 61, loss = 0.56751528\n",
      "Iteration 62, loss = 0.56663640\n",
      "Iteration 63, loss = 0.56580536\n",
      "Iteration 64, loss = 0.56487137\n",
      "Iteration 65, loss = 0.56390141\n",
      "Iteration 66, loss = 0.56292509\n",
      "Iteration 67, loss = 0.56196129\n",
      "Iteration 68, loss = 0.56095747\n",
      "Iteration 69, loss = 0.55994039\n",
      "Iteration 70, loss = 0.55894640\n",
      "Iteration 71, loss = 0.55786686\n",
      "Iteration 72, loss = 0.55675588\n",
      "Iteration 73, loss = 0.55572831\n",
      "Iteration 74, loss = 0.55462448\n",
      "Iteration 75, loss = 0.55362713\n",
      "Iteration 76, loss = 0.55249802\n",
      "Iteration 77, loss = 0.55152250\n",
      "Iteration 78, loss = 0.55046179\n",
      "Iteration 79, loss = 0.54953686\n",
      "Iteration 80, loss = 0.54849281\n",
      "Iteration 81, loss = 0.54753764\n",
      "Iteration 82, loss = 0.54661732\n",
      "Iteration 83, loss = 0.54572332\n",
      "Iteration 84, loss = 0.54472426\n",
      "Iteration 85, loss = 0.54386639\n",
      "Iteration 86, loss = 0.54292009\n",
      "Iteration 87, loss = 0.54213780\n",
      "Iteration 88, loss = 0.54124502\n",
      "Iteration 89, loss = 0.54052419\n",
      "Iteration 90, loss = 0.53987480\n",
      "Iteration 91, loss = 0.53908422\n",
      "Iteration 92, loss = 0.53831110\n",
      "Iteration 93, loss = 0.53751972\n",
      "Iteration 94, loss = 0.53675030\n",
      "Iteration 95, loss = 0.53596934\n",
      "Iteration 96, loss = 0.53510957\n",
      "Iteration 97, loss = 0.53423109\n",
      "Iteration 98, loss = 0.53346410\n",
      "Iteration 99, loss = 0.53262228\n",
      "Iteration 100, loss = 0.53179949\n",
      "Iteration 101, loss = 0.53100673\n",
      "Iteration 102, loss = 0.53023088\n",
      "Iteration 103, loss = 0.52958019\n",
      "Iteration 104, loss = 0.52898629\n",
      "Iteration 105, loss = 0.52813170\n",
      "Iteration 106, loss = 0.52744194\n",
      "Iteration 107, loss = 0.52677172\n",
      "Iteration 108, loss = 0.52604834\n",
      "Iteration 109, loss = 0.52533332\n",
      "Iteration 110, loss = 0.52463544\n",
      "Iteration 111, loss = 0.52390513\n",
      "Iteration 112, loss = 0.52319660\n",
      "Iteration 113, loss = 0.52244401\n",
      "Iteration 114, loss = 0.52169222\n",
      "Iteration 115, loss = 0.52095927\n",
      "Iteration 116, loss = 0.52024368\n",
      "Iteration 117, loss = 0.51954430\n",
      "Iteration 118, loss = 0.51891569\n",
      "Iteration 119, loss = 0.51826749\n",
      "Iteration 120, loss = 0.51764649\n",
      "Iteration 121, loss = 0.51698792\n",
      "Iteration 122, loss = 0.51633407\n",
      "Iteration 123, loss = 0.51561575\n",
      "Iteration 124, loss = 0.51495194\n",
      "Iteration 125, loss = 0.51421674\n",
      "Iteration 126, loss = 0.51353657\n",
      "Iteration 127, loss = 0.51288233\n",
      "Iteration 128, loss = 0.51222620\n",
      "Iteration 129, loss = 0.51151636\n",
      "Iteration 130, loss = 0.51086781\n",
      "Iteration 131, loss = 0.51014011\n",
      "Iteration 132, loss = 0.50944165\n",
      "Iteration 133, loss = 0.50878129\n",
      "Iteration 134, loss = 0.50817415\n",
      "Iteration 135, loss = 0.50749677\n",
      "Iteration 136, loss = 0.50683914\n",
      "Iteration 137, loss = 0.50622147\n",
      "Iteration 138, loss = 0.50555727\n",
      "Iteration 139, loss = 0.50497919\n",
      "Iteration 140, loss = 0.50432016\n",
      "Iteration 141, loss = 0.50381002\n",
      "Iteration 142, loss = 0.50318387\n",
      "Iteration 143, loss = 0.50259780\n",
      "Iteration 144, loss = 0.50201285\n",
      "Iteration 145, loss = 0.50149069\n",
      "Iteration 146, loss = 0.50088108\n",
      "Iteration 147, loss = 0.50033685\n",
      "Iteration 148, loss = 0.49973868\n",
      "Iteration 149, loss = 0.49914085\n",
      "Iteration 150, loss = 0.49861757\n",
      "Iteration 151, loss = 0.49802362\n",
      "Iteration 152, loss = 0.49745573\n",
      "Iteration 153, loss = 0.49691386\n",
      "Iteration 154, loss = 0.49629615\n",
      "Iteration 155, loss = 0.49569077\n",
      "Iteration 156, loss = 0.49511423\n",
      "Iteration 157, loss = 0.49453365\n",
      "Iteration 158, loss = 0.49399668\n",
      "Iteration 159, loss = 0.49346046\n",
      "Iteration 160, loss = 0.49298232\n",
      "Iteration 161, loss = 0.49244800\n",
      "Iteration 162, loss = 0.49206699\n",
      "Iteration 163, loss = 0.49148875\n",
      "Iteration 164, loss = 0.49088659\n",
      "Iteration 165, loss = 0.49030369\n",
      "Iteration 166, loss = 0.48965440\n",
      "Iteration 167, loss = 0.48909205\n",
      "Iteration 168, loss = 0.48852389\n",
      "Iteration 169, loss = 0.48795936\n",
      "Iteration 170, loss = 0.48748044\n",
      "Iteration 171, loss = 0.48699969\n",
      "Iteration 172, loss = 0.48644107\n",
      "Iteration 173, loss = 0.48589669\n",
      "Iteration 174, loss = 0.48527862\n",
      "Iteration 175, loss = 0.48468274\n",
      "Iteration 176, loss = 0.48423426\n",
      "Iteration 177, loss = 0.48360338\n",
      "Iteration 178, loss = 0.48311226\n",
      "Iteration 179, loss = 0.48254451\n",
      "Iteration 180, loss = 0.48203901\n",
      "Iteration 181, loss = 0.48156829\n",
      "Iteration 182, loss = 0.48098844\n",
      "Iteration 183, loss = 0.48046562\n",
      "Iteration 184, loss = 0.47992601\n",
      "Iteration 185, loss = 0.47942513\n",
      "Iteration 186, loss = 0.47893023\n",
      "Iteration 187, loss = 0.47843269\n",
      "Iteration 188, loss = 0.47790261\n",
      "Iteration 189, loss = 0.47740050\n",
      "Iteration 190, loss = 0.47707725\n",
      "Iteration 191, loss = 0.47670231\n",
      "Iteration 192, loss = 0.47626879\n",
      "Iteration 193, loss = 0.47574874\n",
      "Iteration 194, loss = 0.47518099\n",
      "Iteration 195, loss = 0.47466091\n",
      "Iteration 196, loss = 0.47411027\n",
      "Iteration 197, loss = 0.47361572\n",
      "Iteration 198, loss = 0.47324494\n",
      "Iteration 199, loss = 0.47269829\n",
      "Iteration 200, loss = 0.47223054\n",
      "Iteration 201, loss = 0.47180780\n",
      "Iteration 202, loss = 0.47135780\n",
      "Iteration 203, loss = 0.47092442\n",
      "Iteration 204, loss = 0.47051934\n",
      "Iteration 205, loss = 0.47009009\n",
      "Iteration 206, loss = 0.46967672\n",
      "Iteration 207, loss = 0.46926371\n",
      "Iteration 208, loss = 0.46883215\n",
      "Iteration 209, loss = 0.46837965\n",
      "Iteration 210, loss = 0.46795640\n",
      "Iteration 211, loss = 0.46748339\n",
      "Iteration 212, loss = 0.46694227\n",
      "Iteration 213, loss = 0.46639658\n",
      "Iteration 214, loss = 0.46588205\n",
      "Iteration 215, loss = 0.46544490\n",
      "Iteration 216, loss = 0.46492621\n",
      "Iteration 217, loss = 0.46451256\n",
      "Iteration 218, loss = 0.46406557\n",
      "Iteration 219, loss = 0.46365919\n",
      "Iteration 220, loss = 0.46322567\n",
      "Iteration 221, loss = 0.46278204\n",
      "Iteration 222, loss = 0.46231432\n",
      "Iteration 223, loss = 0.46207434\n",
      "Iteration 224, loss = 0.46163557\n",
      "Iteration 225, loss = 0.46115810\n",
      "Iteration 226, loss = 0.46064539\n",
      "Iteration 227, loss = 0.46011064\n",
      "Iteration 228, loss = 0.45958350\n",
      "Iteration 229, loss = 0.45907579\n",
      "Iteration 230, loss = 0.45855763\n",
      "Iteration 231, loss = 0.45809737\n",
      "Iteration 232, loss = 0.45753318\n",
      "Iteration 233, loss = 0.45706450\n",
      "Iteration 234, loss = 0.45668993\n",
      "Iteration 235, loss = 0.45630750\n",
      "Iteration 236, loss = 0.45596925\n",
      "Iteration 237, loss = 0.45551391\n",
      "Iteration 238, loss = 0.45503523\n",
      "Iteration 239, loss = 0.45455132\n",
      "Iteration 240, loss = 0.45406575\n",
      "Iteration 241, loss = 0.45364620\n",
      "Iteration 242, loss = 0.45315901\n",
      "Iteration 243, loss = 0.45258189\n",
      "Iteration 244, loss = 0.45200067\n",
      "Iteration 245, loss = 0.45151453\n",
      "Iteration 246, loss = 0.45100770\n",
      "Iteration 247, loss = 0.45055878\n",
      "Iteration 248, loss = 0.45008500\n",
      "Iteration 249, loss = 0.44971412\n",
      "Iteration 250, loss = 0.44931960\n",
      "Iteration 251, loss = 0.44895065\n",
      "Iteration 252, loss = 0.44844969\n",
      "Iteration 253, loss = 0.44798351\n",
      "Iteration 254, loss = 0.44761008\n",
      "Iteration 255, loss = 0.44702775\n",
      "Iteration 256, loss = 0.44664015\n",
      "Iteration 257, loss = 0.44621309\n",
      "Iteration 258, loss = 0.44595196\n",
      "Iteration 259, loss = 0.44555257\n",
      "Iteration 260, loss = 0.44512901\n",
      "Iteration 261, loss = 0.44475867\n",
      "Iteration 262, loss = 0.44433482\n",
      "Iteration 263, loss = 0.44387246\n",
      "Iteration 264, loss = 0.44346154\n",
      "Iteration 265, loss = 0.44297837\n",
      "Iteration 266, loss = 0.44255706\n",
      "Iteration 267, loss = 0.44212860\n",
      "Iteration 268, loss = 0.44167149\n",
      "Iteration 269, loss = 0.44120868\n",
      "Iteration 270, loss = 0.44070918\n",
      "Iteration 271, loss = 0.44024082\n",
      "Iteration 272, loss = 0.43975965\n",
      "Iteration 273, loss = 0.43938411\n",
      "Iteration 274, loss = 0.43885442\n",
      "Iteration 275, loss = 0.43842786\n",
      "Iteration 276, loss = 0.43801664\n",
      "Iteration 277, loss = 0.43759473\n",
      "Iteration 278, loss = 0.43714967\n",
      "Iteration 279, loss = 0.43669814\n",
      "Iteration 280, loss = 0.43626874\n",
      "Iteration 281, loss = 0.43577497\n",
      "Iteration 282, loss = 0.43535125\n",
      "Iteration 283, loss = 0.43492817\n",
      "Iteration 284, loss = 0.43452602\n",
      "Iteration 285, loss = 0.43414644\n",
      "Iteration 286, loss = 0.43374372\n",
      "Iteration 287, loss = 0.43335565\n",
      "Iteration 288, loss = 0.43301083\n",
      "Iteration 289, loss = 0.43257852\n",
      "Iteration 290, loss = 0.43210991\n",
      "Iteration 291, loss = 0.43169895\n",
      "Iteration 292, loss = 0.43131066\n",
      "Iteration 293, loss = 0.43083802\n",
      "Iteration 294, loss = 0.43047239\n",
      "Iteration 295, loss = 0.43017678\n",
      "Iteration 296, loss = 0.42993768\n",
      "Iteration 297, loss = 0.42962797\n",
      "Iteration 298, loss = 0.42927432\n",
      "Iteration 299, loss = 0.42887729\n",
      "Iteration 300, loss = 0.42843632\n",
      "Iteration 301, loss = 0.42801012\n",
      "Iteration 302, loss = 0.42747050\n",
      "Iteration 303, loss = 0.42703255\n",
      "Iteration 304, loss = 0.42656077\n",
      "Iteration 305, loss = 0.42605815\n",
      "Iteration 306, loss = 0.42567561\n",
      "Iteration 307, loss = 0.42546027\n",
      "Iteration 308, loss = 0.42509125\n",
      "Iteration 309, loss = 0.42474248\n",
      "Iteration 310, loss = 0.42433475\n",
      "Iteration 311, loss = 0.42385083\n",
      "Iteration 312, loss = 0.42333298\n",
      "Iteration 313, loss = 0.42276769\n",
      "Iteration 314, loss = 0.42237359\n",
      "Iteration 315, loss = 0.42197790\n",
      "Iteration 316, loss = 0.42156792\n",
      "Iteration 317, loss = 0.42121606\n",
      "Iteration 318, loss = 0.42082748\n",
      "Iteration 319, loss = 0.42044398\n",
      "Iteration 320, loss = 0.42000319\n",
      "Iteration 321, loss = 0.41955492\n",
      "Iteration 322, loss = 0.41919772\n",
      "Iteration 323, loss = 0.41888554\n",
      "Iteration 324, loss = 0.41847286\n",
      "Iteration 325, loss = 0.41804892\n",
      "Iteration 326, loss = 0.41759655\n",
      "Iteration 327, loss = 0.41712615\n",
      "Iteration 328, loss = 0.41669178\n",
      "Iteration 329, loss = 0.41631484\n",
      "Iteration 330, loss = 0.41592271\n",
      "Iteration 331, loss = 0.41556383\n",
      "Iteration 332, loss = 0.41522143\n",
      "Iteration 333, loss = 0.41489410\n",
      "Iteration 334, loss = 0.41447700\n",
      "Iteration 335, loss = 0.41413392\n",
      "Iteration 336, loss = 0.41363131\n",
      "Iteration 337, loss = 0.41312393\n",
      "Iteration 338, loss = 0.41255592\n",
      "Iteration 339, loss = 0.41231816\n",
      "Iteration 340, loss = 0.41203368\n",
      "Iteration 341, loss = 0.41166869\n",
      "Iteration 342, loss = 0.41138630\n",
      "Iteration 343, loss = 0.41097593\n",
      "Iteration 344, loss = 0.41057538\n",
      "Iteration 345, loss = 0.41019229\n",
      "Iteration 346, loss = 0.40976686\n",
      "Iteration 347, loss = 0.40924989\n",
      "Iteration 348, loss = 0.40881409\n",
      "Iteration 349, loss = 0.40832064\n",
      "Iteration 350, loss = 0.40795467\n",
      "Iteration 351, loss = 0.40774331\n",
      "Iteration 352, loss = 0.40742636\n",
      "Iteration 353, loss = 0.40731044\n",
      "Iteration 354, loss = 0.40696663\n",
      "Iteration 355, loss = 0.40649290\n",
      "Iteration 356, loss = 0.40616189\n",
      "Iteration 357, loss = 0.40575073\n",
      "Iteration 358, loss = 0.40537443\n",
      "Iteration 359, loss = 0.40499119\n",
      "Iteration 360, loss = 0.40469215\n",
      "Iteration 361, loss = 0.40429412\n",
      "Iteration 362, loss = 0.40398673\n",
      "Iteration 363, loss = 0.40362402\n",
      "Iteration 364, loss = 0.40322936\n",
      "Iteration 365, loss = 0.40271568\n",
      "Iteration 366, loss = 0.40224125\n",
      "Iteration 367, loss = 0.40174891\n",
      "Iteration 368, loss = 0.40137902\n",
      "Iteration 369, loss = 0.40106903\n",
      "Iteration 370, loss = 0.40079219\n",
      "Iteration 371, loss = 0.40041728\n",
      "Iteration 372, loss = 0.40010559\n",
      "Iteration 373, loss = 0.39976160\n",
      "Iteration 374, loss = 0.39936790\n",
      "Iteration 375, loss = 0.39889631\n",
      "Iteration 376, loss = 0.39846289\n",
      "Iteration 377, loss = 0.39808959\n",
      "Iteration 378, loss = 0.39763368\n",
      "Iteration 379, loss = 0.39731653\n",
      "Iteration 380, loss = 0.39693473\n",
      "Iteration 381, loss = 0.39655356\n",
      "Iteration 382, loss = 0.39612511\n",
      "Iteration 383, loss = 0.39568663\n",
      "Iteration 384, loss = 0.39529677\n",
      "Iteration 385, loss = 0.39500499\n",
      "Iteration 386, loss = 0.39465658\n",
      "Iteration 387, loss = 0.39426874\n",
      "Iteration 388, loss = 0.39382223\n",
      "Iteration 389, loss = 0.39338792\n",
      "Iteration 390, loss = 0.39312183\n",
      "Iteration 391, loss = 0.39264955\n",
      "Iteration 392, loss = 0.39224630\n",
      "Iteration 393, loss = 0.39186366\n",
      "Iteration 394, loss = 0.39146200\n",
      "Iteration 395, loss = 0.39104823\n",
      "Iteration 396, loss = 0.39067793\n",
      "Iteration 397, loss = 0.39035201\n",
      "Iteration 398, loss = 0.39000166\n",
      "Iteration 399, loss = 0.38974213\n",
      "Iteration 400, loss = 0.38944627\n",
      "Iteration 401, loss = 0.38908420\n",
      "Iteration 402, loss = 0.38886765\n",
      "Iteration 403, loss = 0.38861791\n",
      "Iteration 404, loss = 0.38828197\n",
      "Iteration 405, loss = 0.38802774\n",
      "Iteration 406, loss = 0.38783654\n",
      "Iteration 407, loss = 0.38742690\n",
      "Iteration 408, loss = 0.38705200\n",
      "Iteration 409, loss = 0.38662765\n",
      "Iteration 410, loss = 0.38637875\n",
      "Iteration 411, loss = 0.38608096\n",
      "Iteration 412, loss = 0.38558019\n",
      "Iteration 413, loss = 0.38516253\n",
      "Iteration 414, loss = 0.38469698\n",
      "Iteration 415, loss = 0.38434650\n",
      "Iteration 416, loss = 0.38392525\n",
      "Iteration 417, loss = 0.38347966\n",
      "Iteration 418, loss = 0.38305406\n",
      "Iteration 419, loss = 0.38262332\n",
      "Iteration 420, loss = 0.38228969\n",
      "Iteration 421, loss = 0.38190243\n",
      "Iteration 422, loss = 0.38157659\n",
      "Iteration 423, loss = 0.38129282\n",
      "Iteration 424, loss = 0.38096659\n",
      "Iteration 425, loss = 0.38066610\n",
      "Iteration 426, loss = 0.38031321\n",
      "Iteration 427, loss = 0.37991501\n",
      "Iteration 428, loss = 0.37958128\n",
      "Iteration 429, loss = 0.37913112\n",
      "Iteration 430, loss = 0.37882493\n",
      "Iteration 431, loss = 0.37857027\n",
      "Iteration 432, loss = 0.37814827\n",
      "Iteration 433, loss = 0.37784617\n",
      "Iteration 434, loss = 0.37756762\n",
      "Iteration 435, loss = 0.37731763\n",
      "Iteration 436, loss = 0.37712679\n",
      "Iteration 437, loss = 0.37702378\n",
      "Iteration 438, loss = 0.37694980\n",
      "Iteration 439, loss = 0.37667798\n",
      "Iteration 440, loss = 0.37622565\n",
      "Iteration 441, loss = 0.37586056\n",
      "Iteration 442, loss = 0.37535205\n",
      "Iteration 443, loss = 0.37491211\n",
      "Iteration 444, loss = 0.37450235\n",
      "Iteration 445, loss = 0.37409918\n",
      "Iteration 446, loss = 0.37374162\n",
      "Iteration 447, loss = 0.37338688\n",
      "Iteration 448, loss = 0.37306238\n",
      "Iteration 449, loss = 0.37263485\n",
      "Iteration 450, loss = 0.37219611\n",
      "Iteration 451, loss = 0.37177982\n",
      "Iteration 452, loss = 0.37137493\n",
      "Iteration 453, loss = 0.37092120\n",
      "Iteration 454, loss = 0.37055045\n",
      "Iteration 455, loss = 0.37012532\n",
      "Iteration 456, loss = 0.36975493\n",
      "Iteration 457, loss = 0.36950597\n",
      "Iteration 458, loss = 0.36916922\n",
      "Iteration 459, loss = 0.36887943\n",
      "Iteration 460, loss = 0.36854046\n",
      "Iteration 461, loss = 0.36825909\n",
      "Iteration 462, loss = 0.36802811\n",
      "Iteration 463, loss = 0.36783790\n",
      "Iteration 464, loss = 0.36775270\n",
      "Iteration 465, loss = 0.36750549\n",
      "Iteration 466, loss = 0.36726320\n",
      "Iteration 467, loss = 0.36684334\n",
      "Iteration 468, loss = 0.36635047\n",
      "Iteration 469, loss = 0.36579193\n",
      "Iteration 470, loss = 0.36537381\n",
      "Iteration 471, loss = 0.36489845\n",
      "Iteration 472, loss = 0.36449089\n",
      "Iteration 473, loss = 0.36411862\n",
      "Iteration 474, loss = 0.36378060\n",
      "Iteration 475, loss = 0.36339157\n",
      "Iteration 476, loss = 0.36304628\n",
      "Iteration 477, loss = 0.36280525\n",
      "Iteration 478, loss = 0.36257492\n",
      "Iteration 479, loss = 0.36231883\n",
      "Iteration 480, loss = 0.36210453\n",
      "Iteration 481, loss = 0.36184935\n",
      "Iteration 482, loss = 0.36171259\n",
      "Iteration 483, loss = 0.36134995\n",
      "Iteration 484, loss = 0.36085959\n",
      "Iteration 485, loss = 0.36030782\n",
      "Iteration 486, loss = 0.35974581\n",
      "Iteration 487, loss = 0.35924670\n",
      "Iteration 488, loss = 0.35895237\n",
      "Iteration 489, loss = 0.35877392\n",
      "Iteration 490, loss = 0.35859849\n",
      "Iteration 491, loss = 0.35842277\n",
      "Iteration 492, loss = 0.35815203\n",
      "Iteration 493, loss = 0.35792780\n",
      "Iteration 494, loss = 0.35787472\n",
      "Iteration 495, loss = 0.35769511\n",
      "Iteration 496, loss = 0.35751119\n",
      "Iteration 497, loss = 0.35725171\n",
      "Iteration 498, loss = 0.35670922\n",
      "Iteration 499, loss = 0.35611809\n",
      "Iteration 500, loss = 0.35564554\n",
      "Iteration 501, loss = 0.35524512\n",
      "Iteration 502, loss = 0.35484693\n",
      "Iteration 503, loss = 0.35444739\n",
      "Iteration 504, loss = 0.35396755\n",
      "Iteration 505, loss = 0.35364502\n",
      "Iteration 506, loss = 0.35335073\n",
      "Iteration 507, loss = 0.35312094\n",
      "Iteration 508, loss = 0.35260950\n",
      "Iteration 509, loss = 0.35208197\n",
      "Iteration 510, loss = 0.35187341\n",
      "Iteration 511, loss = 0.35141583\n",
      "Iteration 512, loss = 0.35106624\n",
      "Iteration 513, loss = 0.35085763\n",
      "Iteration 514, loss = 0.35063275\n",
      "Iteration 515, loss = 0.35034114\n",
      "Iteration 516, loss = 0.35005247\n",
      "Iteration 517, loss = 0.34969115\n",
      "Iteration 518, loss = 0.34936928\n",
      "Iteration 519, loss = 0.34899282\n",
      "Iteration 520, loss = 0.34860409\n",
      "Iteration 521, loss = 0.34811163\n",
      "Iteration 522, loss = 0.34765014\n",
      "Iteration 523, loss = 0.34716781\n",
      "Iteration 524, loss = 0.34675727\n",
      "Iteration 525, loss = 0.34643081\n",
      "Iteration 526, loss = 0.34616374\n",
      "Iteration 527, loss = 0.34601009\n",
      "Iteration 528, loss = 0.34588274\n",
      "Iteration 529, loss = 0.34562430\n",
      "Iteration 530, loss = 0.34529128\n",
      "Iteration 531, loss = 0.34493336\n",
      "Iteration 532, loss = 0.34456258\n",
      "Iteration 533, loss = 0.34417669\n",
      "Iteration 534, loss = 0.34387952\n",
      "Iteration 535, loss = 0.34349490\n",
      "Iteration 536, loss = 0.34314591\n",
      "Iteration 537, loss = 0.34291770\n",
      "Iteration 538, loss = 0.34265326\n",
      "Iteration 539, loss = 0.34241899\n",
      "Iteration 540, loss = 0.34215257\n",
      "Iteration 541, loss = 0.34184529\n",
      "Iteration 542, loss = 0.34149603\n",
      "Iteration 543, loss = 0.34122202\n",
      "Iteration 544, loss = 0.34111739\n",
      "Iteration 545, loss = 0.34093795\n",
      "Iteration 546, loss = 0.34066250\n",
      "Iteration 547, loss = 0.34023498\n",
      "Iteration 548, loss = 0.33969114\n",
      "Iteration 549, loss = 0.33921316\n",
      "Iteration 550, loss = 0.33868861\n",
      "Iteration 551, loss = 0.33848166\n",
      "Iteration 552, loss = 0.33832480\n",
      "Iteration 553, loss = 0.33826203\n",
      "Iteration 554, loss = 0.33790798\n",
      "Iteration 555, loss = 0.33745210\n",
      "Iteration 556, loss = 0.33695493\n",
      "Iteration 557, loss = 0.33666096\n",
      "Iteration 558, loss = 0.33636508\n",
      "Iteration 559, loss = 0.33600389\n",
      "Iteration 560, loss = 0.33565955\n",
      "Iteration 561, loss = 0.33533367\n",
      "Iteration 562, loss = 0.33501490\n",
      "Iteration 563, loss = 0.33471011\n",
      "Iteration 564, loss = 0.33438466\n",
      "Iteration 565, loss = 0.33411783\n",
      "Iteration 566, loss = 0.33383228\n",
      "Iteration 567, loss = 0.33358018\n",
      "Iteration 568, loss = 0.33323036\n",
      "Iteration 569, loss = 0.33288995\n",
      "Iteration 570, loss = 0.33265984\n",
      "Iteration 571, loss = 0.33240109\n",
      "Iteration 572, loss = 0.33210981\n",
      "Iteration 573, loss = 0.33184600\n",
      "Iteration 574, loss = 0.33153271\n",
      "Iteration 575, loss = 0.33134275\n",
      "Iteration 576, loss = 0.33093473\n",
      "Iteration 577, loss = 0.33064990\n",
      "Iteration 578, loss = 0.33030119\n",
      "Iteration 579, loss = 0.33006520\n",
      "Iteration 580, loss = 0.32984903\n",
      "Iteration 581, loss = 0.32972549\n",
      "Iteration 582, loss = 0.32967439\n",
      "Iteration 583, loss = 0.32954880\n",
      "Iteration 584, loss = 0.32921135\n",
      "Iteration 585, loss = 0.32864585\n",
      "Iteration 586, loss = 0.32820298\n",
      "Iteration 587, loss = 0.32777117\n",
      "Iteration 588, loss = 0.32752723\n",
      "Iteration 589, loss = 0.32724085\n",
      "Iteration 590, loss = 0.32693350\n",
      "Iteration 591, loss = 0.32665929\n",
      "Iteration 592, loss = 0.32626334\n",
      "Iteration 593, loss = 0.32594262\n",
      "Iteration 594, loss = 0.32567836\n",
      "Iteration 595, loss = 0.32534458\n",
      "Iteration 596, loss = 0.32513878\n",
      "Iteration 597, loss = 0.32487378\n",
      "Iteration 598, loss = 0.32455630\n",
      "Iteration 599, loss = 0.32430109\n",
      "Iteration 600, loss = 0.32388363\n",
      "Iteration 601, loss = 0.32354416\n",
      "Iteration 602, loss = 0.32337551\n",
      "Iteration 603, loss = 0.32323283\n",
      "Iteration 604, loss = 0.32298706\n",
      "Iteration 605, loss = 0.32279468\n",
      "Iteration 606, loss = 0.32261585\n",
      "Iteration 607, loss = 0.32244854\n",
      "Iteration 608, loss = 0.32219820\n",
      "Iteration 609, loss = 0.32187991\n",
      "Iteration 610, loss = 0.32162971\n",
      "Iteration 611, loss = 0.32131754\n",
      "Iteration 612, loss = 0.32111308\n",
      "Iteration 613, loss = 0.32084138\n",
      "Iteration 614, loss = 0.32061688\n",
      "Iteration 615, loss = 0.32032908\n",
      "Iteration 616, loss = 0.32003351\n",
      "Iteration 617, loss = 0.31969813\n",
      "Iteration 618, loss = 0.31939922\n",
      "Iteration 619, loss = 0.31906479\n",
      "Iteration 620, loss = 0.31877049\n",
      "Iteration 621, loss = 0.31849999\n",
      "Iteration 622, loss = 0.31825558\n",
      "Iteration 623, loss = 0.31799418\n",
      "Iteration 624, loss = 0.31773978\n",
      "Iteration 625, loss = 0.31749464\n",
      "Iteration 626, loss = 0.31721398\n",
      "Iteration 627, loss = 0.31690112\n",
      "Iteration 628, loss = 0.31667539\n",
      "Iteration 629, loss = 0.31637290\n",
      "Iteration 630, loss = 0.31621373\n",
      "Iteration 631, loss = 0.31589510\n",
      "Iteration 632, loss = 0.31559277\n",
      "Iteration 633, loss = 0.31531411\n",
      "Iteration 634, loss = 0.31508889\n",
      "Iteration 635, loss = 0.31498339\n",
      "Iteration 636, loss = 0.31489702\n",
      "Iteration 637, loss = 0.31468403\n",
      "Iteration 638, loss = 0.31451307\n",
      "Iteration 639, loss = 0.31423873\n",
      "Iteration 640, loss = 0.31387665\n",
      "Iteration 641, loss = 0.31368909\n",
      "Iteration 642, loss = 0.31333574\n",
      "Iteration 643, loss = 0.31281011\n",
      "Iteration 644, loss = 0.31250707\n",
      "Iteration 645, loss = 0.31219817\n",
      "Iteration 646, loss = 0.31192256\n",
      "Iteration 647, loss = 0.31168586\n",
      "Iteration 648, loss = 0.31150655\n",
      "Iteration 649, loss = 0.31127341\n",
      "Iteration 650, loss = 0.31105062\n",
      "Iteration 651, loss = 0.31079583\n",
      "Iteration 652, loss = 0.31047758\n",
      "Iteration 653, loss = 0.31024406\n",
      "Iteration 654, loss = 0.30991267\n",
      "Iteration 655, loss = 0.30967375\n",
      "Iteration 656, loss = 0.30961735\n",
      "Iteration 657, loss = 0.30952023\n",
      "Iteration 658, loss = 0.30968218\n",
      "Iteration 659, loss = 0.30998131\n",
      "Iteration 660, loss = 0.30993944\n",
      "Iteration 661, loss = 0.30950816\n",
      "Iteration 662, loss = 0.30882128\n",
      "Iteration 663, loss = 0.30836574\n",
      "Iteration 664, loss = 0.30788965\n",
      "Iteration 665, loss = 0.30748273\n",
      "Iteration 666, loss = 0.30716070\n",
      "Iteration 667, loss = 0.30688319\n",
      "Iteration 668, loss = 0.30659663\n",
      "Iteration 669, loss = 0.30632794\n",
      "Iteration 670, loss = 0.30610255\n",
      "Iteration 671, loss = 0.30583659\n",
      "Iteration 672, loss = 0.30556535\n",
      "Iteration 673, loss = 0.30534279\n",
      "Iteration 674, loss = 0.30514203\n",
      "Iteration 675, loss = 0.30488701\n",
      "Iteration 676, loss = 0.30480633\n",
      "Iteration 677, loss = 0.30454475\n",
      "Iteration 678, loss = 0.30426207\n",
      "Iteration 679, loss = 0.30397719\n",
      "Iteration 680, loss = 0.30373207\n",
      "Iteration 681, loss = 0.30337716\n",
      "Iteration 682, loss = 0.30329454\n",
      "Iteration 683, loss = 0.30308892\n",
      "Iteration 684, loss = 0.30296308\n",
      "Iteration 685, loss = 0.30296226\n",
      "Iteration 686, loss = 0.30268510\n",
      "Iteration 687, loss = 0.30240546\n",
      "Iteration 688, loss = 0.30214597\n",
      "Iteration 689, loss = 0.30180079\n",
      "Iteration 690, loss = 0.30147757\n",
      "Iteration 691, loss = 0.30119164\n",
      "Iteration 692, loss = 0.30087625\n",
      "Iteration 693, loss = 0.30076091\n",
      "Iteration 694, loss = 0.30062450\n",
      "Iteration 695, loss = 0.30036085\n",
      "Iteration 696, loss = 0.30015092\n",
      "Iteration 697, loss = 0.29985659\n",
      "Iteration 698, loss = 0.29955299\n",
      "Iteration 699, loss = 0.29935102\n",
      "Iteration 700, loss = 0.29905741\n",
      "Iteration 701, loss = 0.29884338\n",
      "Iteration 702, loss = 0.29863916\n",
      "Iteration 703, loss = 0.29844369\n",
      "Iteration 704, loss = 0.29819548\n",
      "Iteration 705, loss = 0.29807496\n",
      "Iteration 706, loss = 0.29782871\n",
      "Iteration 707, loss = 0.29757416\n",
      "Iteration 708, loss = 0.29729144\n",
      "Iteration 709, loss = 0.29706657\n",
      "Iteration 710, loss = 0.29683619\n",
      "Iteration 711, loss = 0.29665481\n",
      "Iteration 712, loss = 0.29641597\n",
      "Iteration 713, loss = 0.29634142\n",
      "Iteration 714, loss = 0.29602514\n",
      "Iteration 715, loss = 0.29583913\n",
      "Iteration 716, loss = 0.29554583\n",
      "Iteration 717, loss = 0.29542055\n",
      "Iteration 718, loss = 0.29520240\n",
      "Iteration 719, loss = 0.29501409\n",
      "Iteration 720, loss = 0.29480817\n",
      "Iteration 721, loss = 0.29471578\n",
      "Iteration 722, loss = 0.29469381\n",
      "Iteration 723, loss = 0.29467107\n",
      "Iteration 724, loss = 0.29446062\n",
      "Iteration 725, loss = 0.29416024\n",
      "Iteration 726, loss = 0.29376917\n",
      "Iteration 727, loss = 0.29340261\n",
      "Iteration 728, loss = 0.29303195\n",
      "Iteration 729, loss = 0.29275590\n",
      "Iteration 730, loss = 0.29240221\n",
      "Iteration 731, loss = 0.29235854\n",
      "Iteration 732, loss = 0.29216736\n",
      "Iteration 733, loss = 0.29193726\n",
      "Iteration 734, loss = 0.29179270\n",
      "Iteration 735, loss = 0.29162864\n",
      "Iteration 736, loss = 0.29152169\n",
      "Iteration 737, loss = 0.29139095\n",
      "Iteration 738, loss = 0.29115519\n",
      "Iteration 739, loss = 0.29093625\n",
      "Iteration 740, loss = 0.29072855\n",
      "Iteration 741, loss = 0.29046585\n",
      "Iteration 742, loss = 0.29026102\n",
      "Iteration 743, loss = 0.29008375\n",
      "Iteration 744, loss = 0.28988448\n",
      "Iteration 745, loss = 0.28973799\n",
      "Iteration 746, loss = 0.28951561\n",
      "Iteration 747, loss = 0.28934253\n",
      "Iteration 748, loss = 0.28909976\n",
      "Iteration 749, loss = 0.28881601\n",
      "Iteration 750, loss = 0.28855835\n",
      "Iteration 751, loss = 0.28828382\n",
      "Iteration 752, loss = 0.28804025\n",
      "Iteration 753, loss = 0.28780686\n",
      "Iteration 754, loss = 0.28754485\n",
      "Iteration 755, loss = 0.28726539\n",
      "Iteration 756, loss = 0.28701580\n",
      "Iteration 757, loss = 0.28708530\n",
      "Iteration 758, loss = 0.28689998\n",
      "Iteration 759, loss = 0.28670567\n",
      "Iteration 760, loss = 0.28651011\n",
      "Iteration 761, loss = 0.28631879\n",
      "Iteration 762, loss = 0.28599772\n",
      "Iteration 763, loss = 0.28574178\n",
      "Iteration 764, loss = 0.28549823\n",
      "Iteration 765, loss = 0.28523623\n",
      "Iteration 766, loss = 0.28500904\n",
      "Iteration 767, loss = 0.28479483\n",
      "Iteration 768, loss = 0.28452352\n",
      "Iteration 769, loss = 0.28431654\n",
      "Iteration 770, loss = 0.28408753\n",
      "Iteration 771, loss = 0.28392270\n",
      "Iteration 772, loss = 0.28371837\n",
      "Iteration 773, loss = 0.28361737\n",
      "Iteration 774, loss = 0.28345988\n",
      "Iteration 775, loss = 0.28329344\n",
      "Iteration 776, loss = 0.28300001\n",
      "Iteration 777, loss = 0.28297477\n",
      "Iteration 778, loss = 0.28269826\n",
      "Iteration 779, loss = 0.28257714\n",
      "Iteration 780, loss = 0.28241549\n",
      "Iteration 781, loss = 0.28228270\n",
      "Iteration 782, loss = 0.28213401\n",
      "Iteration 783, loss = 0.28204835\n",
      "Iteration 784, loss = 0.28181330\n",
      "Iteration 785, loss = 0.28151527\n",
      "Iteration 786, loss = 0.28129040\n",
      "Iteration 787, loss = 0.28105213\n",
      "Iteration 788, loss = 0.28077700\n",
      "Iteration 789, loss = 0.28059305\n",
      "Iteration 790, loss = 0.28036622\n",
      "Iteration 791, loss = 0.28020765\n",
      "Iteration 792, loss = 0.28005641\n",
      "Iteration 793, loss = 0.27984392\n",
      "Iteration 794, loss = 0.27964902\n",
      "Iteration 795, loss = 0.27929365\n",
      "Iteration 796, loss = 0.27921226\n",
      "Iteration 797, loss = 0.27874940\n",
      "Iteration 798, loss = 0.27856047\n",
      "Iteration 799, loss = 0.27835483\n",
      "Iteration 800, loss = 0.27817959\n",
      "Iteration 801, loss = 0.27793709\n",
      "Iteration 802, loss = 0.27787803\n",
      "Iteration 803, loss = 0.27800419\n",
      "Iteration 804, loss = 0.27815314\n",
      "Iteration 805, loss = 0.27812571\n",
      "Iteration 806, loss = 0.27806479\n",
      "Iteration 807, loss = 0.27782503\n",
      "Iteration 808, loss = 0.27749355\n",
      "Iteration 809, loss = 0.27712534\n",
      "Iteration 810, loss = 0.27670734\n",
      "Iteration 811, loss = 0.27658184\n",
      "Iteration 812, loss = 0.27630090\n",
      "Iteration 813, loss = 0.27608331\n",
      "Iteration 814, loss = 0.27585356\n",
      "Iteration 815, loss = 0.27564436\n",
      "Iteration 816, loss = 0.27545137\n",
      "Iteration 817, loss = 0.27531336\n",
      "Iteration 818, loss = 0.27513980\n",
      "Iteration 819, loss = 0.27490733\n",
      "Iteration 820, loss = 0.27477177\n",
      "Iteration 821, loss = 0.27458387\n",
      "Iteration 822, loss = 0.27446539\n",
      "Iteration 823, loss = 0.27437926\n",
      "Iteration 824, loss = 0.27439708\n",
      "Iteration 825, loss = 0.27429691\n",
      "Iteration 826, loss = 0.27414266\n",
      "Iteration 827, loss = 0.27395769\n",
      "Iteration 828, loss = 0.27365427\n",
      "Iteration 829, loss = 0.27336744\n",
      "Iteration 830, loss = 0.27300580\n",
      "Iteration 831, loss = 0.27279913\n",
      "Iteration 832, loss = 0.27267513\n",
      "Iteration 833, loss = 0.27260862\n",
      "Iteration 834, loss = 0.27242417\n",
      "Iteration 835, loss = 0.27227640\n",
      "Iteration 836, loss = 0.27213147\n",
      "Iteration 837, loss = 0.27194537\n",
      "Iteration 838, loss = 0.27171707\n",
      "Iteration 839, loss = 0.27152040\n",
      "Iteration 840, loss = 0.27130440\n",
      "Iteration 841, loss = 0.27107761\n",
      "Iteration 842, loss = 0.27089268\n",
      "Iteration 843, loss = 0.27077420\n",
      "Iteration 844, loss = 0.27056991\n",
      "Iteration 845, loss = 0.27035661\n",
      "Iteration 846, loss = 0.27011067\n",
      "Iteration 847, loss = 0.26981735\n",
      "Iteration 848, loss = 0.26954648\n",
      "Iteration 849, loss = 0.26935920\n",
      "Iteration 850, loss = 0.26940958\n",
      "Iteration 851, loss = 0.26942179\n",
      "Iteration 852, loss = 0.26940418\n",
      "Iteration 853, loss = 0.26935770\n",
      "Iteration 854, loss = 0.26921048\n",
      "Iteration 855, loss = 0.26918806\n",
      "Iteration 856, loss = 0.26908454\n",
      "Iteration 857, loss = 0.26874256\n",
      "Iteration 858, loss = 0.26825758\n",
      "Iteration 859, loss = 0.26792325\n",
      "Iteration 860, loss = 0.26768500\n",
      "Iteration 861, loss = 0.26735728\n",
      "Iteration 862, loss = 0.26715904\n",
      "Iteration 863, loss = 0.26706719\n",
      "Iteration 864, loss = 0.26734768\n",
      "Iteration 865, loss = 0.26720129\n",
      "Iteration 866, loss = 0.26704871\n",
      "Iteration 867, loss = 0.26679873\n",
      "Iteration 868, loss = 0.26656966\n",
      "Iteration 869, loss = 0.26627766\n",
      "Iteration 870, loss = 0.26601528\n",
      "Iteration 871, loss = 0.26575271\n",
      "Iteration 872, loss = 0.26545045\n",
      "Iteration 873, loss = 0.26546189\n",
      "Iteration 874, loss = 0.26526706\n",
      "Iteration 875, loss = 0.26542861\n",
      "Iteration 876, loss = 0.26548081\n",
      "Iteration 877, loss = 0.26547287\n",
      "Iteration 878, loss = 0.26527422\n",
      "Iteration 879, loss = 0.26493783\n",
      "Iteration 880, loss = 0.26457777\n",
      "Iteration 881, loss = 0.26433466\n",
      "Iteration 882, loss = 0.26400844\n",
      "Iteration 883, loss = 0.26385141\n",
      "Iteration 884, loss = 0.26372800\n",
      "Iteration 885, loss = 0.26354034\n",
      "Iteration 886, loss = 0.26342993\n",
      "Iteration 887, loss = 0.26344777\n",
      "Iteration 888, loss = 0.26323416\n",
      "Iteration 889, loss = 0.26290308\n",
      "Iteration 890, loss = 0.26254087\n",
      "Iteration 891, loss = 0.26230769\n",
      "Iteration 892, loss = 0.26216408\n",
      "Iteration 893, loss = 0.26207801\n",
      "Iteration 894, loss = 0.26217800\n",
      "Iteration 895, loss = 0.26210151\n",
      "Iteration 896, loss = 0.26208058\n",
      "Iteration 897, loss = 0.26197311\n",
      "Iteration 898, loss = 0.26177467\n",
      "Iteration 899, loss = 0.26149083\n",
      "Iteration 900, loss = 0.26120916\n",
      "Iteration 901, loss = 0.26088854\n",
      "Iteration 902, loss = 0.26065115\n",
      "Iteration 903, loss = 0.26041532\n",
      "Iteration 904, loss = 0.26023199\n",
      "Iteration 905, loss = 0.26004687\n",
      "Iteration 906, loss = 0.25993878\n",
      "Iteration 907, loss = 0.25983625\n",
      "Iteration 908, loss = 0.25962228\n",
      "Iteration 909, loss = 0.25950021\n",
      "Iteration 910, loss = 0.25921739\n",
      "Iteration 911, loss = 0.25923561\n",
      "Iteration 912, loss = 0.25908117\n",
      "Iteration 913, loss = 0.25891261\n",
      "Iteration 914, loss = 0.25883242\n",
      "Iteration 915, loss = 0.25865851\n",
      "Iteration 916, loss = 0.25847566\n",
      "Iteration 917, loss = 0.25820321\n",
      "Iteration 918, loss = 0.25797169\n",
      "Iteration 919, loss = 0.25773913\n",
      "Iteration 920, loss = 0.25744333\n",
      "Iteration 921, loss = 0.25722781\n",
      "Iteration 922, loss = 0.25698962\n",
      "Iteration 923, loss = 0.25695581\n",
      "Iteration 924, loss = 0.25674519\n",
      "Iteration 925, loss = 0.25657712\n",
      "Iteration 926, loss = 0.25639821\n",
      "Iteration 927, loss = 0.25657854\n",
      "Iteration 928, loss = 0.25614084\n",
      "Iteration 929, loss = 0.25597028\n",
      "Iteration 930, loss = 0.25580014\n",
      "Iteration 931, loss = 0.25564579\n",
      "Iteration 932, loss = 0.25543638\n",
      "Iteration 933, loss = 0.25518857\n",
      "Iteration 934, loss = 0.25502338\n",
      "Iteration 935, loss = 0.25486003\n",
      "Iteration 936, loss = 0.25480640\n",
      "Iteration 937, loss = 0.25477134\n",
      "Iteration 938, loss = 0.25479823\n",
      "Iteration 939, loss = 0.25466739\n",
      "Iteration 940, loss = 0.25455349\n",
      "Iteration 941, loss = 0.25445514\n",
      "Iteration 942, loss = 0.25447494\n",
      "Iteration 943, loss = 0.25434139\n",
      "Iteration 944, loss = 0.25408090\n",
      "Iteration 945, loss = 0.25389945\n",
      "Iteration 946, loss = 0.25359134\n",
      "Iteration 947, loss = 0.25334221\n",
      "Iteration 948, loss = 0.25304807\n",
      "Iteration 949, loss = 0.25290979\n",
      "Iteration 950, loss = 0.25275871\n",
      "Iteration 951, loss = 0.25261821\n",
      "Iteration 952, loss = 0.25248125\n",
      "Iteration 953, loss = 0.25238442\n",
      "Iteration 954, loss = 0.25219453\n",
      "Iteration 955, loss = 0.25201412\n",
      "Iteration 956, loss = 0.25190143\n",
      "Iteration 957, loss = 0.25171939\n",
      "Iteration 958, loss = 0.25149977\n",
      "Iteration 959, loss = 0.25132673\n",
      "Iteration 960, loss = 0.25121056\n",
      "Iteration 961, loss = 0.25109637\n",
      "Iteration 962, loss = 0.25102678\n",
      "Iteration 963, loss = 0.25101160\n",
      "Iteration 964, loss = 0.25093348\n",
      "Iteration 965, loss = 0.25081035\n",
      "Iteration 966, loss = 0.25068275\n",
      "Iteration 967, loss = 0.25049337\n",
      "Iteration 968, loss = 0.25024289\n",
      "Iteration 969, loss = 0.25012617\n",
      "Iteration 970, loss = 0.24999949\n",
      "Iteration 971, loss = 0.24983072\n",
      "Iteration 972, loss = 0.24962430\n",
      "Iteration 973, loss = 0.24939946\n",
      "Iteration 974, loss = 0.24917959\n",
      "Iteration 975, loss = 0.24904097\n",
      "Iteration 976, loss = 0.24878531\n",
      "Iteration 977, loss = 0.24860954\n",
      "Iteration 978, loss = 0.24852144\n",
      "Iteration 979, loss = 0.24838050\n",
      "Iteration 980, loss = 0.24816206\n",
      "Iteration 981, loss = 0.24802880\n",
      "Iteration 982, loss = 0.24784169\n",
      "Iteration 983, loss = 0.24762126\n",
      "Iteration 984, loss = 0.24748422\n",
      "Iteration 985, loss = 0.24729484\n",
      "Iteration 986, loss = 0.24715578\n",
      "Iteration 987, loss = 0.24703259\n",
      "Iteration 988, loss = 0.24688575\n",
      "Iteration 989, loss = 0.24671542\n",
      "Iteration 990, loss = 0.24655596\n",
      "Iteration 991, loss = 0.24640380\n",
      "Iteration 992, loss = 0.24625691\n",
      "Iteration 993, loss = 0.24605831\n",
      "Iteration 994, loss = 0.24583854\n",
      "Iteration 995, loss = 0.24581654\n",
      "Iteration 996, loss = 0.24559774\n",
      "Iteration 997, loss = 0.24548165\n",
      "Iteration 998, loss = 0.24544229\n",
      "Iteration 999, loss = 0.24531954\n",
      "Iteration 1000, loss = 0.24516821\n",
      "Precisão do Modelo 1: 0.6551724137931034\n",
      "Precisão do Modelo 2: 0.6896551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\larin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação para o Modelo 1:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "no-recurrence-events       0.75      0.75      0.75        40\n",
      "   recurrence-events       0.44      0.44      0.44        18\n",
      "\n",
      "            accuracy                           0.66        58\n",
      "           macro avg       0.60      0.60      0.60        58\n",
      "        weighted avg       0.66      0.66      0.66        58\n",
      "\n",
      "Relatório de Classificação para o Modelo 2:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "no-recurrence-events       0.78      0.78      0.78        40\n",
      "   recurrence-events       0.50      0.50      0.50        18\n",
      "\n",
      "            accuracy                           0.69        58\n",
      "           macro avg       0.64      0.64      0.64        58\n",
      "        weighted avg       0.69      0.69      0.69        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "\n",
    "# Carregar os dados do arquivo CSV\n",
    "data = pd.read_csv('breast-cancer.csv')\n",
    "\n",
    "# Verificar as primeiras linhas para confirmar se os dados foram carregados corretamente\n",
    "print(data.head())\n",
    "\n",
    "# Dividir os dados em features (X) e rótulos (y)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Converter colunas categóricas em variáveis dummy\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Identificação de outliers (opcional, usando Z-score como exemplo)\n",
    "z_scores = np.abs((X - X.mean()) / X.std())\n",
    "X = X[(z_scores < 3).all(axis=1)]\n",
    "y = y[X.index]\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Balanceamento dos dados\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Eliminação de redundância usando PCA (opcional)\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_res)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_pca, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definição de hiperparâmetros para Grid Search\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50,), (50, 100, 50,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Ajuste automático de hiperparâmetros usando Grid Search\n",
    "grid_search = GridSearchCV(MLPClassifier(max_iter=1000, random_state=42), param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "grid_search.fit(X_treino, y_treino)\n",
    "\n",
    "# Melhor modelo obtido pelo Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Avaliação do modelo com melhores hiperparâmetros\n",
    "previsoes = best_model.predict(X_teste)\n",
    "precisao = accuracy_score(y_teste, previsoes)\n",
    "print(\"Precisão do melhor modelo:\", precisao)\n",
    "\n",
    "# Matriz de confusão e relatório de classificação\n",
    "cm = ConfusionMatrix(best_model)\n",
    "cm.fit(X_treino, y_treino)\n",
    "cm.score(X_teste, y_teste)\n",
    "cm.show()\n",
    "\n",
    "print(\"Relatório de Classificação para o Melhor Modelo:\")\n",
    "print(classification_report(y_teste, previsoes))\n",
    "\n",
    "# Avaliação da relação entre taxa de aprendizado e quantidade de épocas\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "epochs = [200, 500, 1000]\n",
    "for lr in learning_rates:\n",
    "    for epoch in epochs:\n",
    "        model = MLPClassifier(max_iter=epoch, learning_rate_init=lr, random_state=42)\n",
    "        model.fit(X_treino, y_treino)\n",
    "        preds = model.predict(X_teste)\n",
    "        acc = accuracy_score(y_teste, preds)\n",
    "        print(f\"Precisão com taxa de aprendizado {lr} e {epoch} épocas: {acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
